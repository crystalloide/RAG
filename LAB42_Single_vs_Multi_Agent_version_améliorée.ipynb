{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystalloide/RAG/blob/main/LAB42_Single_vs_Multi_Agent_version_am%C3%A9lior%C3%A9e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBShD5Olvhse"
      },
      "source": [
        "# LAB42 : Mono Agent versus Multi Agent Interactions\n",
        "\n",
        "**Objectif:** Exp√©rimenter comment plusieurs agents l√©gers coordonnent (ou entrent en conflit) par rapport √† un agent unique accomplissant la m√™me t√¢che.\n",
        "\n",
        "**Dur√©e estim√©e:** 15‚Äì20 minutes\n",
        "\n",
        "**Livrable:** Un notebook qui ex√©cute la m√™me t√¢che en modes (A) single-agent et (B) multi-agent et compare les r√©sultats.\n",
        "\n",
        "---\n",
        "\n",
        "## Architecture\n",
        "\n",
        "- **Blackboard** (m√©moire partag√©e)\n",
        "- **R√¥les** sp√©cialis√©s (Researcher, Planner, Critic)\n",
        "- **Protocole** de messages structur√©\n",
        "- **Comparaison** single-agent vs multi-agent\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Am√©liorations de cette version\n",
        "\n",
        "‚úÖ **Support multi-rounds fonctionnel** : Le Researcher collecte des faits compl√©mentaires √† chaque round\n",
        "\n",
        "‚úÖ **Contexte enrichi** : Prise en compte de l'historique des plans et critiques\n",
        "\n",
        "‚úÖ **Logs d√©taill√©s** : Statistiques apr√®s chaque round\n",
        "\n",
        "‚úÖ **Incr√©mentalit√©** : Chaque round am√©liore le pr√©c√©dent au lieu de r√©p√©ter\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p_TDq1Jvhsf"
      },
      "source": [
        "## 1) Setup :\n",
        "\n",
        "Installation des d√©pendances n√©cessaires."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PJ4M__vhsf"
      },
      "execution_count": 14,
      "outputs": [],
      "source": [
        "# Installation des packages\n",
        "!pip install -q openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVoIMh8Zvhsg"
      },
      "source": [
        "### Configuration de la cl√© API OpenAI\n",
        "\n",
        "‚ö†Ô∏è **Important:** Remplacez `your_api_key_here` par votre vraie cl√© API OpenAI.\n",
        "\n",
        "Dans Google Colab, vous pouvez aussi utiliser les **Secrets** :\n",
        "1. Cliquez sur l'ic√¥ne üîë dans la barre lat√©rale gauche\n",
        "2. Ajoutez un secret nomm√© `OPENAI_API_KEY`\n",
        "3. D√©commentez la m√©thode alternative ci-dessous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viM_4K79vhsg",
        "outputId": "7601ea7e-2546-4367-c874-30751efed395"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Cl√© API OpenAI charg√©e depuis les secrets Colab\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# R√©cup√©rer la cl√© API depuis les secrets Colab\n",
        "# Pour ajouter : cliquez sur üîë dans le panneau de gauche\n",
        "try:\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "    print(\"‚úì Cl√© API OpenAI charg√©e depuis les secrets Colab\")\n",
        "except:\n",
        "    print(\"‚ö† Secrets Colab non configur√©s. Veuillez ajouter OPENAI_API_KEY.\")\n",
        "    print(\"Instructions : Cliquez sur üîë dans le panneau gauche > Ajouter un nouveau secret\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WgGlpD5vhsg"
      },
      "source": [
        "## 2) D√©finition d'une interface minimale pour agent :\n",
        "\n",
        "Chaque agent poss√®de :\n",
        "- **role** : son r√¥le sp√©cifique\n",
        "- **prompt** : instructions syst√®me\n",
        "- **act(state)** : m√©thode retournant un message et des mises √† jour optionnelles du blackboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raCLkwvQvhsg",
        "outputId": "34def43a-06f4-483a-eb32-47f4e940a340"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Structures de base d√©finies (Message, Blackboard, fonction chat)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import uuid\n",
        "import time\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Any, List\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialisation du client OpenAI\n",
        "llm = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "\n",
        "def chat(system: str, user: str, temp: float = 0) -> str:\n",
        "    \"\"\"\n",
        "    Fonction helper pour appeler l'API OpenAI.\n",
        "\n",
        "    Args:\n",
        "        system: Prompt syst√®me d√©finissant le r√¥le\n",
        "        user: Message utilisateur avec le contexte\n",
        "        temp: Temp√©rature (0 = d√©terministe, >0 = cr√©atif)\n",
        "\n",
        "    Returns:\n",
        "        R√©ponse du mod√®le\n",
        "    \"\"\"\n",
        "    r = llm.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=temp,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user}\n",
        "        ]\n",
        "    )\n",
        "    return r.choices[0].message.content.strip()\n",
        "\n",
        "@dataclass\n",
        "class Message:\n",
        "    \"\"\"Message √©chang√© entre agents.\"\"\"\n",
        "    sender: str\n",
        "    content: str\n",
        "    ts: float = field(default_factory=time.time)\n",
        "\n",
        "@dataclass\n",
        "class Blackboard:\n",
        "    \"\"\"\n",
        "    Blackboard (tableau noir) : m√©moire partag√©e entre agents.\n",
        "    - data: dictionnaire de donn√©es structur√©es\n",
        "    - log: historique des messages\n",
        "    \"\"\"\n",
        "    data: Dict[str, Any] = field(default_factory=dict)\n",
        "    log: List[Message] = field(default_factory=list)\n",
        "\n",
        "    def write(self, msg: Message):\n",
        "        \"\"\"Ajoute un message au log.\"\"\"\n",
        "        self.log.append(msg)\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        \"\"\"Met √† jour les donn√©es du blackboard.\"\"\"\n",
        "        self.data.update(kwargs)\n",
        "\n",
        "print(\"‚úì Structures de base d√©finies (Message, Blackboard, fonction chat)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZj4DPoMvhsg"
      },
      "source": [
        "## 3) Cr√©ation des prompts pour chaque r√¥le :\n",
        "\n",
        "D√©finition des prompts pour chaque r√¥le sp√©cialis√© :\n",
        "- **Researcher** : collecte des faits et sources\n",
        "- **Planner** : propose un plan structur√©\n",
        "- **Critic** : identifie les lacunes et am√©liore\n",
        "- **Single Agent** : combine tous les r√¥les"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjkKEepJvhsg",
        "outputId": "009526f4-2284-41e9-cb29-5c7ff6f3890a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Prompts de r√¥les d√©finis\n",
            "  - Researcher: 132 caract√®res\n",
            "  - Planner: 117 caract√®res\n",
            "  - Critic: 120 caract√®res\n",
            "  - Single: 150 caract√®res\n"
          ]
        }
      ],
      "source": [
        "ROLE_RESEARCHER = (\n",
        "    \"Role: Researcher. Read the task & propose 3 concise facts or sources \"\n",
        "    \"to inform a solution. Output as bullet points. No final answer.\"\n",
        ")\n",
        "\n",
        "ROLE_PLANNER = (\n",
        "    \"Role: Planner. Read the latest facts and propose an ordered plan with 3‚Äì5 steps. \"\n",
        "    \"State assumptions and risks briefly.\"\n",
        ")\n",
        "\n",
        "ROLE_CRITIC = (\n",
        "    \"Role: Critic. Review the plan for gaps, conflicts, or missing data. \"\n",
        "    \"Return 2‚Äì3 actionable improvements. No final answer.\"\n",
        ")\n",
        "\n",
        "ROLE_SINGLE = (\n",
        "    \"You are a single agent acting as Researcher, Planner, and Critic at once. \"\n",
        "    \"Given the task, produce facts, a plan, then self-critique with improvements.\"\n",
        ")\n",
        "\n",
        "print(\"‚úì Prompts de r√¥les d√©finis\")\n",
        "print(f\"  - Researcher: {len(ROLE_RESEARCHER)} caract√®res\")\n",
        "print(f\"  - Planner: {len(ROLE_PLANNER)} caract√®res\")\n",
        "print(f\"  - Critic: {len(ROLE_CRITIC)} caract√®res\")\n",
        "print(f\"  - Single: {len(ROLE_SINGLE)} caract√®res\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGbuXNGnvhsh"
      },
      "source": [
        "## 4) D√©finition de la classe pour les agents :\n",
        "\n",
        "Classe `BaseAgent` impl√©mentant le comportement de base d'un agent :\n",
        "- Lecture du contexte (task + blackboard + historique)\n",
        "- Appel au LLM avec son prompt de r√¥le\n",
        "- Retour d'un message structur√©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVa_SDlKvhsh",
        "outputId": "a32061f5-8c83-4098-c24e-2be42ebcb505"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Agents instanci√©s :\n",
            "  - Researcher\n",
            "  - Planner\n",
            "  - Critic\n",
            "  - Solo (single-agent)\n"
          ]
        }
      ],
      "source": [
        "class BaseAgent:\n",
        "    \"\"\"\n",
        "    Agent de base avec un r√¥le et un nom.\n",
        "    \"\"\"\n",
        "    def __init__(self, name: str, role: str):\n",
        "        self.name = name\n",
        "        self.role = role\n",
        "\n",
        "    def act(self, task: str, bb: Blackboard) -> Message:\n",
        "        \"\"\"\n",
        "        Ex√©cute une action bas√©e sur le task et l'√©tat du blackboard.\n",
        "\n",
        "        Args:\n",
        "            task: T√¢che √† accomplir\n",
        "            bb: Blackboard contenant l'√©tat partag√©\n",
        "\n",
        "        Returns:\n",
        "            Message contenant la r√©ponse de l'agent\n",
        "        \"\"\"\n",
        "        # Construction du contexte\n",
        "        context = (\n",
        "            f\"Task:\\n{task}\\n\\nBlackboard:\\n{bb.data}\\n\\n\"\n",
        "            f\"Conversation so far:\\n\" +\n",
        "            \"\\n\".join([\n",
        "                f\"- {m.sender}: {m.content[:200]}\"\n",
        "                for m in bb.log[-6:]  # Garde les 6 derniers messages\n",
        "            ])\n",
        "        )\n",
        "\n",
        "        # Appel au LLM\n",
        "        out = chat(system=self.role, user=context)\n",
        "\n",
        "        return Message(sender=self.name, content=out)\n",
        "\n",
        "# Instanciation des agents sp√©cialis√©s\n",
        "researcher = BaseAgent(\"Researcher\", ROLE_RESEARCHER)\n",
        "planner    = BaseAgent(\"Planner\", ROLE_PLANNER)\n",
        "critic     = BaseAgent(\"Critic\", ROLE_CRITIC)\n",
        "single     = BaseAgent(\"Solo\", ROLE_SINGLE)\n",
        "\n",
        "print(\"‚úì Agents instanci√©s :\")\n",
        "print(f\"  - {researcher.name}\")\n",
        "print(f\"  - {planner.name}\")\n",
        "print(f\"  - {critic.name}\")\n",
        "print(f\"  - {single.name} (single-agent)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POk56i7gvhsh"
      },
      "source": [
        "## 5) Turn-based multi-agent loop : ‚ú® Version am√©lior√©e ‚ú®\n",
        "\n",
        "**Protocole:** Researcher ‚Üí Planner ‚Üí Critic ‚Üí Planner (r√©vision)\n",
        "\n",
        "### üÜï Am√©liorations cl√©s\n",
        "\n",
        "1. **Awareness multi-rounds** : Le Researcher sait qu'il doit fournir des faits **compl√©mentaires** aux rounds suivants\n",
        "2. **Contexte enrichi** : Prise en compte de l'historique (4 derniers messages au lieu de 2)\n",
        "3. **Historique des plans** : Stockage de toutes les versions pour tra√ßabilit√©\n",
        "4. **Statistiques d√©taill√©es** : Affichage apr√®s chaque round\n",
        "5. **Mode verbose** : Possibilit√© de d√©sactiver les logs pour benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCBV-gryvhsh",
        "outputId": "3cd0e836-1167-4e93-cd73-2475a66ba6a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Fonction multi_agent_run AM√âLIOR√âE d√©finie\n"
          ]
        }
      ],
      "source": [
        "def summarize_last(msgs: List[Message], role: str) -> str:\n",
        "    \"\"\"\n",
        "    R√©sume les derniers messages pour un r√¥le sp√©cifique.\n",
        "    Utilise le LLM pour condenser l'information.\n",
        "\n",
        "    Args:\n",
        "        msgs: Liste des messages\n",
        "        role: R√¥le pour lequel on r√©sume\n",
        "\n",
        "    Returns:\n",
        "        R√©sum√© condens√©\n",
        "    \"\"\"\n",
        "    if not msgs:\n",
        "        return \"\"\n",
        "\n",
        "    # Prendre plus de contexte pour les rounds suivants (4 au lieu de 2)\n",
        "    joined = \"\\n\".join([m.content for m in msgs[-4:]])\n",
        "    return chat(system=f\"Summarize key points for {role}.\", user=joined)\n",
        "\n",
        "def multi_agent_run(task: str, rounds: int = 1, verbose: bool = True) -> Blackboard:\n",
        "    \"\"\"\n",
        "    Ex√©cute le workflow multi-agent avec support de multiples rounds.\n",
        "\n",
        "    Args:\n",
        "        task: T√¢che √† accomplir\n",
        "        rounds: Nombre d'it√©rations du cycle complet\n",
        "        verbose: Afficher les logs d√©taill√©s\n",
        "\n",
        "    Returns:\n",
        "        Blackboard final avec tous les r√©sultats\n",
        "    \"\"\"\n",
        "    bb = Blackboard(data={\n",
        "        \"task\": task,\n",
        "        \"facts\": [],        # Liste de tous les faits collect√©s\n",
        "        \"plans\": [],        # Historique des plans (pour tra√ßabilit√©)\n",
        "        \"critiques\": [],    # Historique des critiques\n",
        "        \"plan\": \"\",         # Plan actuel (le plus r√©cent)\n",
        "        \"critique\": \"\"      # Critique actuelle\n",
        "    })\n",
        "\n",
        "    for r in range(rounds):\n",
        "        if verbose:\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"üîÑ ROUND {r+1}/{rounds}\")\n",
        "            print('='*70)\n",
        "\n",
        "        # 1) Researcher collecte des faits (avec awareness des rounds pr√©c√©dents)\n",
        "        if verbose:\n",
        "            print(\"  üìö Researcher: collecte des faits...\")\n",
        "\n",
        "        researcher_context = task\n",
        "        if r > 0:\n",
        "            # Apr√®s le 1er round, demander des faits compl√©mentaires\n",
        "            researcher_context += (\n",
        "                f\"\\n\\nPrevious facts collected:\\n\" +\n",
        "                \"\\n\".join([f\"- {f[:100]}...\" for f in bb.data[\"facts\"][-3:]]) +\n",
        "                \"\\n\\nProvide NEW complementary facts or deeper insights.\"\n",
        "            )\n",
        "\n",
        "        m1 = researcher.act(researcher_context, bb)\n",
        "        bb.write(m1)\n",
        "        bb.data[\"facts\"].append(m1.content)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    ‚úì {len(m1.content)} caract√®res collect√©s\")\n",
        "\n",
        "        # 2) Planner propose un plan\n",
        "        if verbose:\n",
        "            print(\"  üìã Planner: cr√©ation du plan...\")\n",
        "\n",
        "        ctx = summarize_last(bb.log, \"Planner\")\n",
        "        planner_prompt = task + \"\\n\\nContext:\\n\" + ctx\n",
        "\n",
        "        if r > 0:\n",
        "            # Mentionner le plan pr√©c√©dent pour am√©lioration incr√©mentale\n",
        "            planner_prompt += (\n",
        "                f\"\\n\\nPrevious plan (Round {r}):\\n{bb.data['plans'][-1][:200]}...\"\n",
        "                \"\\n\\nRefine and improve based on new facts.\"\n",
        "            )\n",
        "\n",
        "        m2 = planner.act(planner_prompt, bb)\n",
        "        bb.write(m2)\n",
        "        bb.data[\"plan\"] = m2.content\n",
        "        bb.data[\"plans\"].append(m2.content)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    ‚úì Plan v{r+1} g√©n√©r√© ({len(m2.content)} caract√®res)\")\n",
        "\n",
        "        # 3) Critic review le plan\n",
        "        if verbose:\n",
        "            print(\"  üîç Critic: analyse et critique...\")\n",
        "\n",
        "        ctx = summarize_last(bb.log, \"Critic\")\n",
        "        m3 = critic.act(task + \"\\n\\nContext:\\n\" + ctx, bb)\n",
        "        bb.write(m3)\n",
        "        bb.data[\"critique\"] = m3.content\n",
        "        bb.data[\"critiques\"].append(m3.content)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    ‚úì Critique g√©n√©r√©e ({len(m3.content)} caract√®res)\")\n",
        "\n",
        "        # 4) Planner r√©vise le plan selon la critique\n",
        "        if verbose:\n",
        "            print(\"  ‚úèÔ∏è  Planner: r√©vision du plan...\")\n",
        "\n",
        "        ctx = summarize_last(bb.log, \"Planner\")\n",
        "        m4 = planner.act(\n",
        "            task + \"\\n\\nRevise plan per critique:\\n\" + ctx, bb\n",
        "        )\n",
        "        bb.write(m4)\n",
        "        bb.data[\"plan\"] = m4.content  # Plan r√©vis√© devient le plan actuel\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    ‚úì Plan r√©vis√© ({len(m4.content)} caract√®res)\")\n",
        "\n",
        "        bb.update(round=r+1)\n",
        "\n",
        "        # Afficher un r√©sum√© du round\n",
        "        if verbose:\n",
        "            print(f\"\\n  üìä Round {r+1} termin√©:\")\n",
        "            print(f\"    - Total messages: {len(bb.log)}\")\n",
        "            print(f\"    - Total faits: {len(bb.data['facts'])}\")\n",
        "            print(f\"    - Plans g√©n√©r√©s: {len(bb.data['plans'])}\")\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"‚úÖ Multi-agent workflow termin√©\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"üìà Statistiques finales:\")\n",
        "        print(f\"  - {rounds} round(s) compl√©t√©(s)\")\n",
        "        print(f\"  - {len(bb.log)} messages √©chang√©s\")\n",
        "        print(f\"  - {len(bb.data['facts'])} faits collect√©s\")\n",
        "        print(f\"  - {len(bb.data['plans'])} versions de plan\")\n",
        "\n",
        "    return bb\n",
        "\n",
        "print(\"‚úì Fonction multi_agent_run AM√âLIOR√âE d√©finie\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPRdOoONvhsh"
      },
      "source": [
        "## 6) Gestion en mode Mono/single-agent  :\n",
        "\n",
        "L'agent unique combine tous les r√¥les en une seule invocation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yke-0DW9vhsh",
        "outputId": "3a30aaf4-6349-468d-99f2-0c8a254e0577"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Fonction single_agent_run d√©finie\n"
          ]
        }
      ],
      "source": [
        "def single_agent_run(task: str) -> Blackboard:\n",
        "    bb = Blackboard(data={\"task\": task})\n",
        "    print(\"\\nü§ñ Single-agent: traitement...\")\n",
        "    m = single.act(task, bb)\n",
        "    bb.write(m)\n",
        "    bb.update(final=m.content)\n",
        "    print(\"‚úì Single-agent termin√©\")\n",
        "    return bb\n",
        "\n",
        "print(\"‚úì Fonction single_agent_run d√©finie\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlNYIC-Fvhsh"
      },
      "source": [
        "## 7) Test avec 1 round puis 2 rounds\n",
        "\n",
        "### Test avec 1 round"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51mmwyISvhsh",
        "outputId": "8a35ec16-baa0-4529-afa1-2ecc703f58bb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "T√ÇCHE √Ä ACCOMPLIR\n",
            "======================================================================\n",
            "Design a 3-email outreach sequence for a B2B AI tool targeting healthcare analytics leaders. Include subject lines and a clear CTA each.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "TASK = (\n",
        "    \"Design a 3-email outreach sequence for a B2B AI tool targeting \"\n",
        "    \"healthcare analytics leaders. Include subject lines and a clear CTA each.\"\n",
        ")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"T√ÇCHE √Ä ACCOMPLIR\")\n",
        "print(\"=\"*70)\n",
        "print(TASK)\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20bAlrnZvhsi",
        "outputId": "6a7fcf35-89dc-4474-f8af-07ee8f73b208"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üîÑ ROUND 1/1\n",
            "======================================================================\n",
            "  üìö Researcher: collecte des faits...\n",
            "    ‚úì 793 caract√®res collect√©s\n",
            "  üìã Planner: cr√©ation du plan...\n",
            "    ‚úì Plan v1 g√©n√©r√© (2351 caract√®res)\n",
            "  üîç Critic: analyse et critique...\n",
            "    ‚úì Critique g√©n√©r√©e (1093 caract√®res)\n",
            "  ‚úèÔ∏è  Planner: r√©vision du plan...\n",
            "    ‚úì Plan r√©vis√© (3704 caract√®res)\n",
            "\n",
            "  üìä Round 1 termin√©:\n",
            "    - Total messages: 4\n",
            "    - Total faits: 1\n",
            "    - Plans g√©n√©r√©s: 1\n",
            "\n",
            "======================================================================\n",
            "‚úÖ Multi-agent workflow termin√©\n",
            "======================================================================\n",
            "üìà Statistiques finales:\n",
            "  - 1 round(s) compl√©t√©(s)\n",
            "  - 4 messages √©chang√©s\n",
            "  - 1 faits collect√©s\n",
            "  - 1 versions de plan\n"
          ]
        }
      ],
      "source": [
        "# Test avec 1 ROUND\n",
        "bb_multi_1 = multi_agent_run(TASK, rounds=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94e7LXtRvhsi"
      },
      "source": [
        "### Test avec 2 rounds (pour voir l'am√©lioration incr√©mentale)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWm7QNyhvhsi",
        "outputId": "61549311-e650-4ddd-a9bb-417cc400b16c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üîÑ ROUND 1/2\n",
            "======================================================================\n",
            "  üìö Researcher: collecte des faits...\n",
            "    ‚úì 741 caract√®res collect√©s\n",
            "  üìã Planner: cr√©ation du plan...\n",
            "    ‚úì Plan v1 g√©n√©r√© (2502 caract√®res)\n",
            "  üîç Critic: analyse et critique...\n",
            "    ‚úì Critique g√©n√©r√©e (1365 caract√®res)\n",
            "  ‚úèÔ∏è  Planner: r√©vision du plan...\n",
            "    ‚úì Plan r√©vis√© (3410 caract√®res)\n",
            "\n",
            "  üìä Round 1 termin√©:\n",
            "    - Total messages: 4\n",
            "    - Total faits: 1\n",
            "    - Plans g√©n√©r√©s: 1\n",
            "\n",
            "======================================================================\n",
            "üîÑ ROUND 2/2\n",
            "======================================================================\n",
            "  üìö Researcher: collecte des faits...\n",
            "    ‚úì 753 caract√®res collect√©s\n",
            "  üìã Planner: cr√©ation du plan...\n",
            "    ‚úì Plan v2 g√©n√©r√© (3502 caract√®res)\n",
            "  üîç Critic: analyse et critique...\n",
            "    ‚úì Critique g√©n√©r√©e (1459 caract√®res)\n",
            "  ‚úèÔ∏è  Planner: r√©vision du plan...\n",
            "    ‚úì Plan r√©vis√© (3439 caract√®res)\n",
            "\n",
            "  üìä Round 2 termin√©:\n",
            "    - Total messages: 8\n",
            "    - Total faits: 2\n",
            "    - Plans g√©n√©r√©s: 2\n",
            "\n",
            "======================================================================\n",
            "‚úÖ Multi-agent workflow termin√©\n",
            "======================================================================\n",
            "üìà Statistiques finales:\n",
            "  - 2 round(s) compl√©t√©(s)\n",
            "  - 8 messages √©chang√©s\n",
            "  - 2 faits collect√©s\n",
            "  - 2 versions de plan\n"
          ]
        }
      ],
      "source": [
        "# Test avec 2 ROUNDS\n",
        "bb_multi_2 = multi_agent_run(TASK, rounds=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SZIo34cvhsi",
        "outputId": "c756748f-2b6c-41c2-ade7-821a79da817b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ Single-agent: traitement...\n",
            "‚úì Single-agent termin√©\n"
          ]
        }
      ],
      "source": [
        "# Single-agent pour comparaison\n",
        "bb_single = single_agent_run(TASK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaw84aWYvhsi"
      },
      "source": [
        "## 8) Comparaison des r√©sultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ8eixI0vhsi",
        "outputId": "71b75be0-6838-49c9-9b71-96cc6705ee08"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "COMPARAISON: 1 ROUND vs 2 ROUNDS vs SINGLE-AGENT\n",
            "======================================================================\n",
            "\n",
            "üìä MULTI-AGENT 1 ROUND:\n",
            "  - Messages: 4\n",
            "  - Faits: 1\n",
            "  - Plans: 1\n",
            "\n",
            "üìä MULTI-AGENT 2 ROUNDS:\n",
            "  - Messages: 8\n",
            "  - Faits: 2\n",
            "  - Plans: 2\n",
            "\n",
            "üìä SINGLE-AGENT:\n",
            "  - Messages: 1\n",
            "\n",
            "======================================================================\n",
            "PLAN FINAL (2 rounds):\n",
            "======================================================================\n",
            "### Ordered Plan for Email Outreach Sequence for B2B AI Tool Targeting Healthcare Analytics Leaders\n",
            "\n",
            "1. **Email 1: Introduction to AI Benefits in Healthcare**\n",
            "   - **Subject Line**: Unlock 30% Improvement in Patient Outcomes with AI\n",
            "   - **Body**: \n",
            "     Hi [Recipient's Name],\n",
            "     \n",
            "     As a leader in healthcare analytics, you know that enhancing patient care and operational efficiency is paramount. According to McKinsey, organizations leveraging AI for analytics can improve outcomes by up to 30%. Our AI tool is specifically designed to address challenges like data integration and predictive analytics, which many healthcare organizations face today.\n",
            "     \n",
            "     **CTA**: Schedule a 15-minute call to explore how our solution can transform your analytics strategy and address your unique challenges.\n",
            "\n",
            "2. **Email 2: Highlighting Executive Support for AI Adoption**\n",
            "   - **Subject Line**: Join 83% of Executives Embracing AI in Healthcare\n",
            "   - **Body**: \n",
            "     Hi [Recipient's Name],\n",
            "     \n",
            "     Did you know that 83% of healthcare executives view AI as a key driver of innovation? As the industry evolves, adopting AI technologies is essential for staying competitive. Our AI tool not only aligns with this trend but also empowers your team to make data-driven decisions that enhance patient care. For instance, [insert a brief success story or case study relevant to the recipient's organization].\n",
            "     \n",
            "     **CTA**: Download our free whitepaper on AI in healthcare analytics to see how your peers are leveraging these technologies and the results they are achieving.\n",
            "\n",
            "3. **Email 3: Emphasizing Data-Driven Decision Making**\n",
            "   - **Subject Line**: Transform Your Decision-Making with Actionable Insights\n",
            "   - **Body**: \n",
            "     Hi [Recipient's Name],\n",
            "     \n",
            "     The HIMSS emphasizes the importance of data-driven decision-making in healthcare. Our AI tool provides actionable insights that can help you make informed decisions quickly and effectively. Imagine the impact on your organization when you can predict trends and improve patient outcomes with confidence. To illustrate, our tool features real-time analytics and customizable dashboards tailored to your needs.\n",
            "     \n",
            "     **CTA**: Request a personalized demo to see our AI tool in action and discover how it can meet your specific needs. Act now to take advantage of our limited-time offer for early adopters!\n",
            "\n",
            "4. **Follow-Up Strategy**\n",
            "   - **Follow-Up Email**: If no response is received after the third email, send a follow-up email one week later, reiterating the key benefits and including a new CTA, such as a limited-time offer or an invitation to a webinar on AI in healthcare analytics.\n",
            "\n",
            "### Assumptions\n",
            "- The target audience is familiar with AI and its potential benefits in healthcare.\n",
            "- The recipients have decision-making authority or influence in their organizations regarding technology adoption.\n",
            "- The emails will be sent in a timely manner, allowing for follow-up and engagement.\n",
            "\n",
            "### Risks\n",
            "- Low engagement rates if the emails are not personalized or relevant to the recipient's specific challenges.\n",
            "- Potential competition from other AI solutions in the market.\n",
            "- Recipients may have existing solutions that they are satisfied with, making them less open to new offerings.\n",
            "\n",
            "This structured approach aims to enhance engagement and response rates through targeted messaging, strategic follow-ups, and a focus on personalization and competitive differentiation.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARAISON: 1 ROUND vs 2 ROUNDS vs SINGLE-AGENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìä MULTI-AGENT 1 ROUND:\")\n",
        "print(f\"  - Messages: {len(bb_multi_1.log)}\")\n",
        "print(f\"  - Faits: {len(bb_multi_1.data['facts'])}\")\n",
        "print(f\"  - Plans: {len(bb_multi_1.data['plans'])}\")\n",
        "\n",
        "print(\"\\nüìä MULTI-AGENT 2 ROUNDS:\")\n",
        "print(f\"  - Messages: {len(bb_multi_2.log)}\")\n",
        "print(f\"  - Faits: {len(bb_multi_2.data['facts'])}\")\n",
        "print(f\"  - Plans: {len(bb_multi_2.data['plans'])}\")\n",
        "\n",
        "print(\"\\nüìä SINGLE-AGENT:\")\n",
        "print(f\"  - Messages: {len(bb_single.log)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PLAN FINAL (2 rounds):\")\n",
        "print(\"=\"*70)\n",
        "print(bb_multi_2.data.get('plan', ''))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H83og6ysvhsi",
        "outputId": "40d8040c-df48-456b-cd2d-fb6a4daee467"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "√âVOLUTION DES FAITS (2 rounds)\n",
            "======================================================================\n",
            "\n",
            "[Round 1] Fait 1:\n",
            "- **Fact 1**: According to a report by McKinsey, healthcare organizations that leverage AI for analytics can improve patient outcomes and operational efficiency by up to 30%. This highlights the potential value of AI tools in healthcare analytics.\n",
            "\n",
            "- **Fact 2**: A survey by Deloitte found that 83% o...\n",
            "\n",
            "[Round 1] Fait 2:\n",
            "- **Fact 4**: A study by Accenture found that AI applications in healthcare could save the industry up to $150 billion annually by 2026, indicating significant cost-saving potential that can be highlighted in outreach efforts.\n",
            "  \n",
            "- **Fact 5**: Research from the Journal of Medical Internet Research s...\n"
          ]
        }
      ],
      "source": [
        "# √âvolution des faits entre rounds\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"√âVOLUTION DES FAITS (2 rounds)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, fact in enumerate(bb_multi_2.data['facts'], 1):\n",
        "    round_num = (i + 3) // 4  # 4 messages par round\n",
        "    print(f\"\\n[Round {round_num}] Fait {i}:\")\n",
        "    print(fact[:300] + \"...\" if len(fact) > 300 else fact)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6JEDzUBvhsi"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "### üéØ Ce que vous avez appris\n",
        "\n",
        "1. **Multi-rounds fonctionnent** : Chaque round am√©liore le pr√©c√©dent\n",
        "2. **Awareness contextuelle** : Les agents savent o√π ils en sont dans le processus\n",
        "3. **Incr√©mentalit√©** : Le Researcher apporte de nouveaux faits √† chaque round\n",
        "4. **Trade-off co√ªt/qualit√©** : 2 rounds = 2x plus d'appels LLM mais meilleure qualit√©\n",
        "\n",
        "### üî¨ Exp√©rimentations sugg√©r√©es\n",
        "\n",
        "- Tester avec 3-4 rounds : √† quel moment observe-t-on des rendements d√©croissants ?\n",
        "- Ajouter un crit√®re de convergence : arr√™ter si la critique devient positive\n",
        "- Comparer les co√ªts : mesurer tokens utilis√©s par round\n",
        "- Tester sur des t√¢ches plus complexes n√©cessitant vraiment plusieurs it√©rations"
      ]
    }
  ]
}