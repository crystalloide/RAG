{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystalloide/RAG/blob/main/LAB02_LLM_Cycles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZsxFy0Gafy0"
      },
      "source": [
        "# Lab 2: Cycles de \"prompt-r√©ponse\" avec un LLM\n",
        "\n",
        "**Objectifs :**  \n",
        "- Comprendre et exp√©rimenter la mani√®re dont un LLM traite les invites,\n",
        "- Comment il conserve le contexte\n",
        "- et comment il produit des r√©ponses lors de plusieurs √©changes.\n",
        "\n",
        "**Dur√©e estim√©e :** 75‚Äì90 minutes\n",
        "\n",
        "**Livrable :** Notebook illustrant les cycles invite-r√©ponse √† un seul tour, √† plusieurs tours et avec r√©initialisation du contexte.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvpXD_FGafy2"
      },
      "source": [
        "## Step 1: Pr√©-requis (5 min)\n",
        "\n",
        "Installation des d√©pendances n√©cessaires et configuration de l'API OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1c17nkxafy2",
        "outputId": "a33a1184-fae7-4270-e40f-fbf65bee2a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì D√©pendances install√©es avec succ√®s\n"
          ]
        }
      ],
      "source": [
        "# Installation des d√©pendances\n",
        "!pip install openai python-dotenv -q\n",
        "print(\"‚úì D√©pendances install√©es avec succ√®s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFhFC3Zrafy3",
        "outputId": "8eacfbd1-a178-4f10-e4bb-8fca94de234e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì API Key configured successfully\n"
          ]
        }
      ],
      "source": [
        "# Configuration de l'API OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get API key from Colab Secrets (add it in the Secrets manager: üîë icon on left panel)\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Or if running locally with .env file:\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "\n",
        "print(\"‚úì API Key configured successfully\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hm5wq3Wafy4"
      },
      "source": [
        "## Step 2: D√©finition d'une fonction auxiliaire \"chat_cycle\" (10 min)\n",
        "\n",
        "Cr√©er une fonction r√©utilisable pour les cycles conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU-MrouVafy4",
        "outputId": "17692eb7-b752-4a0b-aada-cb4e27e931c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Fonction chat_cycle() d√©finie\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "def chat_cycle(messages, model=\"gpt-4o-mini\", temperature=0.7):\n",
        "    \"\"\"\n",
        "    Ex√©cute un cycle de chat avec l'API OpenAI.\n",
        "\n",
        "    Args:\n",
        "        messages (list): Liste des messages {\"role\": ..., \"content\": ...}\n",
        "        model (str): Mod√®le √† utiliser (d√©faut: gpt-4o-mini)\n",
        "        temperature (float): Contr√¥le la cr√©ativit√© (0.0-1.0)\n",
        "\n",
        "    Returns:\n",
        "        str: Contenu de la r√©ponse du mod√®le\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Erreur: {str(e)}\"\n",
        "\n",
        "print(\"‚úì Fonction chat_cycle() d√©finie\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzdG3p6pafy4"
      },
      "source": [
        "## Step 3: Single-Turn Prompting (10 min)\n",
        "\n",
        "Tester les prompts simples et observer la variabilit√©."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PBRBYVhafy4",
        "outputId": "4e53e867-5261-4bd2-f504-051de2ef8829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SINGLE-TURN PROMPTING: Test 1 - Prompt sans contrainte\n",
            "============================================================\n",
            "\n",
            "Run 1:\n",
            "Agentic AI refers to artificial intelligence systems that possess the ability to make independent decisions and take actions in pursuit of specific goals, often exhibiting a level of autonomy and adaptability in their operations.\n",
            "\n",
            "Run 2 (m√™me prompt):\n",
            "Agentic AI refers to artificial intelligence systems that possess the capacity to act autonomously and make decisions based on their own assessments of situations, rather than merely following pre-defined instructions.\n",
            "\n",
            "üìå Observation: Les r√©ponses sont-elles identiques? False\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"SINGLE-TURN PROMPTING: Test 1 - Prompt sans contrainte\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Explain Agentic AI in one sentence.\"}]\n",
        "response1 = chat_cycle(messages)\n",
        "print(f\"\\nRun 1:\\n{response1}\")\n",
        "\n",
        "# Relancer pour observer la variabilit√©\n",
        "response2 = chat_cycle(messages)\n",
        "print(f\"\\nRun 2 (m√™me prompt):\\n{response2}\")\n",
        "\n",
        "print(f\"\\nüìå Observation: Les r√©ponses sont-elles identiques? {response1 == response2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmJ5MaPpafy5",
        "outputId": "4719d0c1-82bf-43f6-a05b-af8242197b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SINGLE-TURN PROMPTING: Test 2 - Prompt avec contrainte\n",
            "============================================================\n",
            "\n",
            "R√©ponse:\n",
            "Agentic AI possesses autonomy, making independent decisions in specific contexts.\n",
            "\n",
            "üìå Nombre de mots: 10\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SINGLE-TURN PROMPTING: Test 2 - Prompt avec contrainte\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "messages_constrained = [\n",
        "    {\"role\": \"user\", \"content\": \"Explain Agentic AI in exactly 10 words. Count your words.\"}\n",
        "]\n",
        "response_constrained = chat_cycle(messages_constrained)\n",
        "print(f\"\\nR√©ponse:\\n{response_constrained}\")\n",
        "\n",
        "word_count = len(response_constrained.split())\n",
        "print(f\"\\nüìå Nombre de mots: {word_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfBblj87afy5"
      },
      "source": [
        "## Step 4: Multi-Turn Conversations (15 min)\n",
        "\n",
        "Exp√©rimenter avec plusieurs tours et observer la persistance du contexte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFN8qVdrafy5",
        "outputId": "eee6500d-75da-48b7-f610-b4ee7bfa2e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "MULTI-TURN CONVERSATION: Building Context\n",
            "============================================================\n",
            "\n",
            "--- Turn 1 ---\n",
            "User: What is an AI agent?\n",
            "\n",
            "Assistant: An AI agent is a system that can perceive its environment, make decisions, and take actions to achieve specific goals based on the information it gathers. These agents can operate autonomously or semi-autonomously and are designed to solve problems or perform tasks that typically require human intelligence.\n",
            "\n",
            "Key characteristics of AI agents include:\n",
            "\n",
            "1. **Perception**: AI agents can observe their environment using sensors or data inputs (e.g., cameras, microphones, or data streams).\n",
            "\n",
            "2. **Reasoning and Decision-Making**: They process the information they perceive to reason about their environment and make decisions. This often involves using algorithms, heuristics, or machine learning techniques.\n",
            "\n",
            "3. **Action**: Once a decision is made, the agent can take actions in the environment, which can include physical movements (in the case of robots) or digital actions (like sending messages or making calculations).\n",
            "\n",
            "4. **Autonomy**: Many AI agents operate independently without human intervention, although they can also be designed to work alongside humans.\n",
            "\n",
            "5. **Learning**: Some AI agents have the capability to learn from their experiences, improving their performance over time through techniques such as reinforcement learning.\n",
            "\n",
            "AI agents can be found in various applications, including virtual assistants (like Siri or Alexa), autonomous vehicles, recommendation systems, and even complex systems in distributed environments such as multi-agent systems in robotics and simulations.\n",
            "\n",
            "--- Turn 2 ---\n",
            "User: Can you give me an example in healthcare?\n",
            "\n",
            "Assistant: Certainly! One notable example of an AI agent in healthcare is a **clinical decision support system (CDSS)**.\n",
            "\n",
            "### Example: Clinical Decision Support System (CDSS)\n",
            "\n",
            "**Functionality:**\n",
            "A CDSS is designed to assist healthcare providers in making clinical decisions by analyzing patient data and providing evidence-based recommendations. Here‚Äôs how it works:\n",
            "\n",
            "1. **Perception**: The AI agent gathers data from various sources, such as electronic health records (EHRs), lab results, medical imaging, and patient history. It may also incorporate real-time data from wearable health devices.\n",
            "\n",
            "2. **Reasoning and Decision-Making**: The AI agent uses algorithms to analyze the collected data, comparing it against medical guidelines, clinical studies, and best practices. For instance, it might assess symptoms and lab results to identify potential diagnoses or recommend treatment options.\n",
            "\n",
            "3. **Action**: Based on its analysis, the CDSS generates alerts or suggestions for healthcare providers. For example, if a patient is at risk of a specific condition due to their health data, the system might alert the physician to consider additional testing or preventive measures.\n",
            "\n",
            "4. **Autonomy**: While the CDSS operates autonomously in processing data and generating recommendations, it is typically used in conjunction with human healthcare providers, who make the final decisions regarding patient care.\n",
            "\n",
            "5. **Learning**: Many modern CDSSs use machine learning techniques to improve their recommendations over time. As they process more cases, they can refine their algorithms to enhance accuracy and relevance.\n",
            "\n",
            "### Impact:\n",
            "The use of a CDSS can lead to improved patient outcomes by:\n",
            "- Reducing diagnostic errors.\n",
            "- Providing timely interventions.\n",
            "- Supporting personalized treatment plans based on individual patient data.\n",
            "- Enhancing the efficiency of healthcare delivery by streamlining decision-making processes.\n",
            "\n",
            "Overall, AI agents like CDSS exemplify how artificial intelligence can augment healthcare practices, ultimately leading to better patient care and operational efficiency.\n",
            "\n",
            "--- Turn 3 ---\n",
            "User: How does this relate to what you mentioned earlier?\n",
            "\n",
            "Assistant: The example of a **Clinical Decision Support System (CDSS)** in healthcare directly relates to the characteristics of an **AI agent** that I mentioned earlier. Here's how the CDSS embodies those characteristics:\n",
            "\n",
            "1. **Perception**: \n",
            "   - The CDSS perceives its environment by gathering data from electronic health records (EHRs), lab results, patient histories, and real-time data from wearables. This mirrors the perception aspect of AI agents, where they collect information from their environment to inform their actions.\n",
            "\n",
            "2. **Reasoning and Decision-Making**: \n",
            "   - The CDSS applies algorithms to analyze the collected data, akin to how AI agents reason about their environment. It interprets patient data against medical guidelines and clinical evidence to generate recommendations, reflecting the decision-making process of AI agents.\n",
            "\n",
            "3. **Action**: \n",
            "   - Once the CDSS has analyzed the data, it takes action by providing alerts or recommendations to healthcare providers. This corresponds to the action characteristic of AI agents, which involves executing decisions based on perceived information.\n",
            "\n",
            "4. **Autonomy**: \n",
            "   - While the CDSS operates autonomously in processing data and providing insights, it does so in partnership with human healthcare providers. This aligns with the concept of AI agents being able to operate independently while also having the capability to work collaboratively with humans.\n",
            "\n",
            "5. **Learning**: \n",
            "   - Many CDSSs incorporate machine learning to improve their recommendations over time, which is a feature of AI agents. This ability to learn from past cases and refine decision-making is crucial for enhancing the effectiveness of the system.\n",
            "\n",
            "### Summary:\n",
            "In summary, the CDSS exemplifies how an AI agent functions in a real-world application, particularly in healthcare. It illustrates the process of perception, reasoning, action, autonomy, and learning‚Äîkey characteristics that define AI agents. By integrating these elements, the CDSS helps healthcare providers make better-informed decisions, ultimately improving patient care and outcomes.\n",
            "\n",
            "üìå Observation: L'assistant maintient-il le contexte des tours pr√©c√©dents? Oui!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"MULTI-TURN CONVERSATION: Building Context\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Initialiser la conversation avec un syst√®me prompt\n",
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a friendly teaching assistant specializing in AI and distributed systems.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is an AI agent?\"}\n",
        "]\n",
        "\n",
        "# Tour 1\n",
        "print(\"\\n--- Turn 1 ---\")\n",
        "print(\"User: What is an AI agent?\")\n",
        "reply1 = chat_cycle(conversation)\n",
        "print(f\"\\nAssistant: {reply1}\")\n",
        "\n",
        "# Ajouter la r√©ponse √† la conversation\n",
        "conversation.append({\"role\": \"assistant\", \"content\": reply1})\n",
        "conversation.append({\"role\": \"user\", \"content\": \"Can you give me an example in healthcare?\"})\n",
        "\n",
        "# Tour 2\n",
        "print(\"\\n--- Turn 2 ---\")\n",
        "print(\"User: Can you give me an example in healthcare?\")\n",
        "reply2 = chat_cycle(conversation)\n",
        "print(f\"\\nAssistant: {reply2}\")\n",
        "\n",
        "# Ajouter pour le tour 3\n",
        "conversation.append({\"role\": \"assistant\", \"content\": reply2})\n",
        "conversation.append({\"role\": \"user\", \"content\": \"How does this relate to what you mentioned earlier?\"})\n",
        "\n",
        "# Tour 3\n",
        "print(\"\\n--- Turn 3 ---\")\n",
        "print(\"User: How does this relate to what you mentioned earlier?\")\n",
        "reply3 = chat_cycle(conversation)\n",
        "print(f\"\\nAssistant: {reply3}\")\n",
        "\n",
        "print(\"\\nüìå Observation: L'assistant maintient-il le contexte des tours pr√©c√©dents? Oui!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20G0Biiaafy5"
      },
      "source": [
        "## Step 5: Context Window Experiment (15 min)\n",
        "\n",
        "Tester les limites de la fen√™tre de contexte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkqPFIpPafy5",
        "outputId": "21953592-7ebe-4415-df5c-253705764f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CONTEXT WINDOW EXPERIMENT: Testing Limits\n",
            "============================================================\n",
            "\n",
            "[Injecting long article...]\n",
            "Assistant: Article read and understood.\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"CONTEXT WINDOW EXPERIMENT: Testing Limits\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cr√©er un long article √† injecter\n",
        "long_article = \"\"\"\n",
        "# The Evolution of Artificial Intelligence\n",
        "\n",
        "Artificial Intelligence (AI) has evolved dramatically over the past six decades. From the early days of\n",
        "symbolic reasoning and expert systems in the 1970s, through the neural network revolution of the 2010s,\n",
        "to the large language models of today, AI has transformed from theoretical computer science to practical\n",
        "tools that power our digital lives.\n",
        "\n",
        "The journey began with Alan Turing's question: \"Can machines think?\" This simple question sparked decades\n",
        "of research. Early AI systems like ELIZA and SHRDLU demonstrated that machines could simulate conversation\n",
        "and understand limited domains. Expert systems of the 1980s brought AI to industry, encoding human expertise\n",
        "in rule-based systems.\n",
        "\n",
        "The winter periods‚Äîtimes when funding dried up and expectations outpaced capabilities‚Äîtaught the field\n",
        "valuable lessons about the dangers of overpromising. Yet each winter was followed by spring: new paradigms\n",
        "emerged, new data became available, and computing power increased exponentially.\n",
        "\n",
        "The deep learning revolution of the 2010s changed everything. Convolutional neural networks conquered image\n",
        "recognition. Recurrent networks learned language. Transformers, introduced in 2017, enabled the scale of\n",
        "models we see today. GPT models, BERT, and their successors demonstrated that scaling up language models\n",
        "on internet-scale data could produce surprisingly capable systems.\n",
        "\n",
        "Today, we stand at an inflection point. Large language models can write code, explain complex concepts,\n",
        "and engage in nuanced reasoning. Multimodal models understand both images and text. And yet, current systems\n",
        "still struggle with tasks that humans find trivial: reasoning about causality, understanding physical\n",
        "intuition, and maintaining consistency over long documents.\n",
        "\n",
        "The next frontiers are agentic AI‚Äîsystems that can plan, act, and iterate‚Äîand multiagent systems where\n",
        "multiple AI entities collaborate and compete. These developments promise to make AI more useful, but also\n",
        "raise important questions about alignment, safety, and societal impact.\n",
        "\"\"\"\n",
        "\n",
        "context_conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a knowledgeable AI assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Please read this article carefully:\\n{long_article}\\n\\nWhen you're done, just say 'Article read and understood.'\"}\n",
        "]\n",
        "\n",
        "print(\"\\n[Injecting long article...]\")\n",
        "ack = chat_cycle(context_conversation)\n",
        "print(f\"Assistant: {ack}\")\n",
        "\n",
        "context_conversation.append({\"role\": \"assistant\", \"content\": ack})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N69pJvqkafy6",
        "outputId": "c79a3f08-150a-413b-fdd1-d61da6581c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Question 1: D√©but de l'article ---\n",
            "Q: Who first asked 'Can machines think'?\n",
            "A: The question \"Can machines think?\" was first posed by Alan Turing.\n",
            "\n",
            "--- Question 2: Milieu de l'article ---\n",
            "Q: What was the deep learning revolution?\n",
            "A: The deep learning revolution refers to a significant advancement in artificial intelligence that began in the early 2010s, characterized by the development and application of deep neural networks. This revolution transformed various fields, particularly in areas like image and language processing.\n",
            "\n",
            "Key aspects include:\n",
            "\n",
            "1. **Convolutional Neural Networks (CNNs)**: These networks excelled at image recognition tasks, significantly improving the accuracy of computer vision applications.\n",
            "\n",
            "2. **Recurrent Neural Networks (RNNs)**: These networks were particularly effective in processing sequential data, making them suitable for tasks involving language, such as translation and speech recognition.\n",
            "\n",
            "3. **Transformers**: Introduced in 2017, transformers revolutionized natural language processing by enabling the training of large-scale models that could handle vast amounts of data. They facilitated the development of powerful language models like GPT and BERT.\n",
            "\n",
            "Overall, the deep learning revolution marked a shift from traditional machine learning techniques to more sophisticated models that leverage large datasets and increased computing power, leading to remarkable advancements in the capabilities of AI systems.\n",
            "\n",
            "--- Question 3: Fin de l'article ---\n",
            "Q: What are the next frontiers mentioned in the article?\n",
            "A: The next frontiers mentioned in the article are:\n",
            "\n",
            "1. **Agentic AI**: These are systems that can plan, act, and iterate, implying a level of autonomy in decision-making and actions.\n",
            "\n",
            "2. **Multiagent Systems**: These involve multiple AI entities that can collaborate and compete with each other, which could enhance the capabilities and applications of AI.\n",
            "\n",
            "These developments promise to make AI more useful but also raise important questions about alignment, safety, and societal impact.\n",
            "\n",
            "üìå Observation: Le mod√®le se souvient-il de d√©tails du d√©but, du milieu, et de la fin?\n"
          ]
        }
      ],
      "source": [
        "# Maintenant, poser plusieurs questions pour voir o√π le contexte s'estompe\n",
        "print(\"\\n--- Question 1: D√©but de l'article ---\")\n",
        "q1 = \"Who first asked 'Can machines think'?\"\n",
        "context_conversation.append({\"role\": \"user\", \"content\": q1})\n",
        "reply_q1 = chat_cycle(context_conversation)\n",
        "print(f\"Q: {q1}\")\n",
        "print(f\"A: {reply_q1}\")\n",
        "context_conversation.append({\"role\": \"assistant\", \"content\": reply_q1})\n",
        "\n",
        "print(\"\\n--- Question 2: Milieu de l'article ---\")\n",
        "q2 = \"What was the deep learning revolution?\"\n",
        "context_conversation.append({\"role\": \"user\", \"content\": q2})\n",
        "reply_q2 = chat_cycle(context_conversation)\n",
        "print(f\"Q: {q2}\")\n",
        "print(f\"A: {reply_q2}\")\n",
        "context_conversation.append({\"role\": \"assistant\", \"content\": reply_q2})\n",
        "\n",
        "print(\"\\n--- Question 3: Fin de l'article ---\")\n",
        "q3 = \"What are the next frontiers mentioned in the article?\"\n",
        "context_conversation.append({\"role\": \"user\", \"content\": q3})\n",
        "reply_q3 = chat_cycle(context_conversation)\n",
        "print(f\"Q: {q3}\")\n",
        "print(f\"A: {reply_q3}\")\n",
        "\n",
        "print(\"\\nüìå Observation: Le mod√®le se souvient-il de d√©tails du d√©but, du milieu, et de la fin?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIxD9vndafy6"
      },
      "source": [
        "## Step 6: Controlled Output Cycles (15 min)\n",
        "\n",
        "Tester les formats de sortie structur√©s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3aMYi1Bafy6",
        "outputId": "971b32b3-8b21-4f44-b909-b9f208e26351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CONTROLLED OUTPUT CYCLES: Testing Formats\n",
            "============================================================\n",
            "\n",
            "--- Test 1: JSON Format ---\n",
            "```json\n",
            "[\n",
            "    {\n",
            "        \"name\": \"Reinforcement Learning\",\n",
            "        \"description\": \"A type of machine learning where agents learn to make decisions by receiving rewards or penalties based on their actions, enabling them to optimize performance over time.\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Natural Language Processing (NLP)\",\n",
            "        \"description\": \"A field of AI that focuses on the interaction between computers and humans through natural language, enabling agents to understand, interpret, and respond to human language.\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Computer Vision\",\n",
            "        \"description\": \"An area of AI that enables agents to interpret and understand visual information from the world, allowing them to recognize objects, track movements, and analyze images.\"\n",
            "    }\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"CONTROLLED OUTPUT CYCLES: Testing Formats\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test 1: JSON\n",
        "print(\"\\n--- Test 1: JSON Format ---\")\n",
        "messages_json = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a JSON-only assistant. Always respond with valid JSON.\"},\n",
        "    {\"role\": \"user\", \"content\": \"List 3 tools used in Agentic AI in JSON format with 'name' and 'description' fields.\"}\n",
        "]\n",
        "response_json = chat_cycle(messages_json)\n",
        "print(response_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KReU9jgafy6",
        "outputId": "1c5a270c-c094-4ff3-cb92-b4fe3a24e979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test 2: Bullet List Format ---\n",
            "- **Reinforcement Learning Frameworks**: Tools like OpenAI Gym and TensorFlow Agents that enable agents to learn optimal behaviors through trial and error.\n",
            "- **Natural Language Processing Libraries**: Libraries such as Hugging Face Transformers and SpaCy for understanding and generating human language.\n",
            "- **Simulation Environments**: Platforms like Unity ML-Agents and Gazebo that provide realistic scenarios for training and testing AI agents.\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Bullet points\n",
        "print(\"\\n--- Test 2: Bullet List Format ---\")\n",
        "messages_bullet = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a bullet-point expert. Always respond using bullet points.\"},\n",
        "    {\"role\": \"user\", \"content\": \"List 3 tools used in Agentic AI as bullet points.\"}\n",
        "]\n",
        "response_bullet = chat_cycle(messages_bullet)\n",
        "print(response_bullet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv5bfJQDafy6",
        "outputId": "b34af769-39be-4d79-b2a7-ebbd6e0fbdc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test 3: Table Format (Markdown) ---\n",
            "Here's a table detailing three agentic AI tools, their main features, and their use cases:\n",
            "\n",
            "| AI Tool          | Main Features                                     | Use Cases                                         |\n",
            "|------------------|---------------------------------------------------|--------------------------------------------------|\n",
            "| OpenAI GPT-3     | - Natural language understanding                   | - Content generation (blogs, articles, etc.)    |\n",
            "|                  | - Conversational capabilities                       | - Customer support (chatbots)                    |\n",
            "|                  | - Text summarization                               | - Virtual assistants                               |\n",
            "|                  | - Language translation                             |                                                  |\n",
            "|------------------|---------------------------------------------------|--------------------------------------------------|\n",
            "| IBM Watson       | - Advanced data analytics                          | - Healthcare diagnostics                          |\n",
            "|                  | - Natural language processing                      | - Sentiment analysis in social media             |\n",
            "|                  | - Machine learning integration                     | - Fraud detection in finance                      |\n",
            "|                  | - Visual recognition                               | - Personalized marketing strategies               |\n",
            "|------------------|---------------------------------------------------|--------------------------------------------------|\n",
            "| Google DeepMind   | - Reinforcement learning                           | - Game development (AI opponents)                |\n",
            "|                  | - Neural networks                                  | - Robotics (autonomous navigation)               |\n",
            "|                  | - Predictive modeling                              | - Energy consumption optimization                 |\n",
            "|                  | - Real-time data processing                        | - Healthcare (predicting patient outcomes)       |\n",
            "\n",
            "Feel free to ask for more details or additional tools!\n",
            "\n",
            "üìå Observation: Quel format est le plus facilement parsable par un programme?\n"
          ]
        }
      ],
      "source": [
        "# Test 3: Table format\n",
        "print(\"\\n--- Test 3: Table Format (Markdown) ---\")\n",
        "messages_table = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a table expert. Always respond using Markdown tables.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Create a table with 3 agentic AI tools, their main features, and use cases.\"}\n",
        "]\n",
        "response_table = chat_cycle(messages_table)\n",
        "print(response_table)\n",
        "\n",
        "print(\"\\nüìå Observation: Quel format est le plus facilement parsable par un programme?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P6fW3C8afy6"
      },
      "source": [
        "## Step 7: Mini Project - Q&A Agent Simulation (15-20 min)\n",
        "\n",
        "Construire une boucle interactive qui maintient le contexte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgDCFkWpafy6",
        "outputId": "712dab2c-1e66-4caa-efca-520a3f9144c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "MINI PROJECT: Interactive Q&A Agent\n",
            "============================================================\n",
            "\n",
            "Cet agent √©ducatif maintient la contexte √† travers plusieurs questions.\n",
            "Tapez 'exit' ou 'quit' pour terminer.\n",
            "Posez des questions li√©es pour voir le maintien du contexte!\n",
            "\n",
            "\n",
            "[Turn 1]\n",
            "üë§ User: What is RAG (Retrieval-Augmented Generation)?\n",
            "ü§ñ AI: Retrieval-Augmented Generation (RAG) is a hybrid approach that combines the strengths of information retrieval and natural language generation. In RAG systems, a model retrieves relevant documents or information from a large corpus based on a query and then uses that information to generate a more informed and contextually relevant response.\n",
            "\n",
            "The RAG architecture typically involves two main components:\n",
            "\n",
            "1. **Retriever**: This component searches a knowledge base or a document corpus to find relevant pieces of information related to a user's query. It employs techniques such as TF-IDF, BM25, or more advanced neural retrieval methods.\n",
            "\n",
            "2. **Generator**: After retrieving the relevant documents, the generator processes this information to produce a coherent and contextually appropriate response. It usually relies on language models, such as transformers, to generate text.\n",
            "\n",
            "This approach is particularly beneficial in scenarios where up-to-date or specialized information is required, as it allows the model to access external knowledge rather than relying solely on pre-existing training data. \n",
            "\n",
            "Would you like to know more about how RAG systems can be implemented or their applications?\n",
            "\n",
            "[Turn 2]\n",
            "üë§ User: How does memory help an AI agent?\n",
            "ü§ñ AI: Memory plays a crucial role in enhancing the capabilities of an AI agent by allowing it to retain, recall, and utilize information over time. Here are some key ways in which memory benefits an AI agent:\n",
            "\n",
            "1. **Contextual Awareness**: Memory allows an AI agent to keep track of past interactions and maintain context over the course of a conversation or task. This enables more relevant and coherent responses.\n",
            "\n",
            "2. **Learning from Experience**: By storing previous experiences, an AI agent can learn from successes and failures, adapt its behavior, and improve its performance over time.\n",
            "\n",
            "3. **Personalization**: Memory enables an AI agent to remember user preferences and past interactions, allowing for personalized responses and recommendations, which enhances user satisfaction.\n",
            "\n",
            "4. **Efficiency**: When an agent can recall previously learned information or solutions, it can solve problems more quickly without needing to reprocess all relevant data from scratch.\n",
            "\n",
            "5. **Knowledge Retention**: Memory systems can store vast amounts of information that an agent can access when needed, thus enabling it to answer complex queries or provide detailed information.\n",
            "\n",
            "In the context of agentic AI and systems like RAG, integrating memory can enhance the overall functionality, as the agent can retrieve information from both its memory and external sources to generate more informed and contextually relevant responses.\n",
            "\n",
            "Would you like to explore specific types of memory architectures or their implementation in AI systems?\n",
            "\n",
            "[Turn 3]\n",
            "üë§ User: Give me an analogy relating RAG to something in daily life.\n",
            "ü§ñ AI: A useful analogy for Retrieval-Augmented Generation (RAG) is comparing it to a chef preparing a dish using a recipe book.\n",
            "\n",
            "1. **The Recipe Book (Retriever)**: Just like a chef consults a recipe book to find specific recipes based on the ingredients they have or the type of dish they want to create, a RAG system retrieves relevant documents or information from a large corpus based on a user's query.\n",
            "\n",
            "2. **Cooking (Generator)**: Once the chef has found the right recipe, they follow the steps and combine the ingredients to create the final dish. Similarly, after retrieving the relevant information, the RAG system uses that data to generate a coherent and contextually appropriate response.\n",
            "\n",
            "In this analogy, the chef's ability to choose the right recipe and adapt it to their style mirrors how RAG combines retrieval and generation to produce informed outputs. Just as a chef can enhance a dish by incorporating personal flair or additional ingredients, RAG can enhance responses by integrating retrieved information into a coherent narrative.\n",
            "\n",
            "Would you like to delve deeper into any specific aspects of RAG or explore more analogies?\n",
            "\n",
            "[Turn 4]\n",
            "üë§ User: How would you combine these concepts in a real system?\n",
            "ü§ñ AI: Combining the concepts of Retrieval-Augmented Generation (RAG) and memory in a real system involves integrating components that can effectively retrieve information, generate responses, and retain context over time. Here‚Äôs a high-level overview of how you could design such a system:\n",
            "\n",
            "1. **Architecture Design**:\n",
            "   - **Retriever Module**: Implement a retrieval system that employs techniques like vector embeddings (e.g., using models like BERT or Sentence Transformers) to index and search a document corpus efficiently. This module should be capable of retrieving relevant documents based on user queries or previous interactions.\n",
            "  \n",
            "   - **Generator Module**: Utilize a generative language model (e.g., GPT-3 or similar) that can take the retrieved documents and the user‚Äôs query to produce coherent and contextually appropriate responses. This model will generate text by conditioning on both the user input and the retrieved information.\n",
            "\n",
            "2. **Memory Integration**:\n",
            "   - **Short-term Memory**: Implement a temporary memory component that stores recent interactions and context. This would allow the system to maintain ongoing conversations and reference previous questions or answers, enhancing contextual awareness.\n",
            "\n",
            "   - **Long-term Memory**: Develop a more permanent memory system that retains important user preferences, historical interactions, and significant information that may not need to be recalled every time but can enhance personalization. This could be structured as a database or knowledge graph.\n",
            "\n",
            "3. **Interaction Flow**:\n",
            "   - **User Query**: The user inputs a question or request.\n",
            "   - **Context Check**: The system checks short-term memory to see if relevant context exists from recent interactions.\n",
            "   - **Information Retrieval**: The retriever searches the document corpus for relevant information based on the current query, possibly also taking the short-term memory into account.\n",
            "   - **Response Generation**: The generator combines the retrieved information and any relevant context from memory to produce a response.\n",
            "   - **Memory Update**: After the interaction, the system updates both short-term and long-term memory with new insights, user preferences, or important information for future interactions.\n",
            "\n",
            "4. **Feedback Loop**:\n",
            "   - Incorporate a feedback mechanism where users can indicate whether the information provided was useful or relevant. This feedback can help refine both the retrieval and generation processes over time.\n",
            "\n",
            "By combining RAG with memory, the system would not only provide accurate and contextually relevant responses but also evolve its understanding of the user, leading to a more personalized and efficient interaction over time.\n",
            "\n",
            "Would you like to explore specific technologies or tools that can be used to implement this system?\n",
            "\n",
            "============================================================\n",
            "Questions pr√©d√©finies termin√©es.\n",
            "Vous pouvez continuer √† poser des questions ou taper 'exit'.\n",
            "============================================================\n",
            "\n",
            "üë§ User: Quel mod√®le de LLM conseilles-tu ?\n",
            "ü§ñ AI: Le choix d'un mod√®le de langage (LLM) d√©pend de plusieurs facteurs, notamment l'application sp√©cifique, les ressources disponibles et les besoins en mati√®re de performance et de personnalisation. Voici quelques recommandations bas√©es sur diff√©rents sc√©narios :\n",
            "\n",
            "1. **GPT-3.5 / GPT-4 (OpenAI)**:\n",
            "   - **Utilisation**: Id√©al pour des applications g√©n√©rales de g√©n√©ration de texte, de conversation, et de r√©ponse aux questions.\n",
            "   - **Avantages**: Excellente qualit√© de g√©n√©ration de texte, grande capacit√© de compr√©hension du contexte, et largement accessible via une API.\n",
            "\n",
            "2. **BERT (Bidirectional Encoder Representations from Transformers)**:\n",
            "   - **Utilisation**: Bien adapt√© pour des t√¢ches de compr√©hension du langage naturel, comme l'extraction d'information et la classification de texte.\n",
            "   - **Avantages**: Excellente performance sur des t√¢ches o√π la compr√©hension du contexte est cruciale, mais pas sp√©cifiquement con√ßu pour la g√©n√©ration de texte.\n",
            "\n",
            "3. **T5 (Text-to-Text Transfer Transformer)**:\n",
            "   - **Utilisation**: Polyvalent, car il traite toutes les t√¢ches de NLP comme des t√¢ches de g√©n√©ration de texte, ce qui le rend adapt√© pour la traduction, le r√©sum√©, et la r√©ponse aux questions.\n",
            "   - **Avantages**: Capable de g√©rer une vari√©t√© de t√¢ches avec un seul mod√®le.\n",
            "\n",
            "4. **DistilBERT**:\n",
            "   - **Utilisation**: Une version all√©g√©e de BERT, id√©ale pour des applications n√©cessitant moins de ressources tout en maintenant une performance raisonnable.\n",
            "   - **Avantages**: Moins gourmand en calcul et plus rapide tout en √©tant capable de fournir des r√©sultats comp√©titifs.\n",
            "\n",
            "5. **Llama (Meta)**:\n",
            "   - **Utilisation**: Mod√®le de langage open-source qui peut √™tre utilis√© pour des applications vari√©es.\n",
            "   - **Avantages**: Acc√®s libre et possibilit√© de personnalisation selon des besoins sp√©cifiques.\n",
            "\n",
            "6. **Claude (Anthropic)**:\n",
            "   - **Utilisation**: Con√ßu pour √™tre plus align√© sur des valeurs √©thiques et de s√©curit√©, adapt√© pour des interactions plus sensibles.\n",
            "   - **Avantages**: Ax√© sur la s√©curit√© et l'√©thique, ce qui peut √™tre important pour certaines applications.\n",
            "\n",
            "En r√©sum√©, si vous recherchez une solution robuste pour la g√©n√©ration de texte, GPT-3.5 ou GPT-4 pourrait √™tre le meilleur choix. Pour des t√¢ches plus sp√©cifiques de compr√©hension ou d'extraction, BERT ou T5 seraient plus appropri√©s. Si vous avez des contraintes de ressources, envisagez des mod√®les comme DistilBERT. \n",
            "\n",
            "Souhaitez-vous explorer des cas d'utilisation sp√©cifiques ou des exemples d'impl√©mentation avec ces mod√®les ?\n",
            "\n",
            "============================================================\n",
            "Questions pr√©d√©finies termin√©es.\n",
            "Vous pouvez continuer √† poser des questions ou taper 'exit'.\n",
            "============================================================\n",
            "\n",
            "üë§ User: exit\n",
            "\n",
            "‚úì Agent simulation ended. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"MINI PROJECT: Interactive Q&A Agent\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nCet agent √©ducatif maintient la contexte √† travers plusieurs questions.\")\n",
        "print(\"Tapez 'exit' ou 'quit' pour terminer.\")\n",
        "print(\"Posez des questions li√©es pour voir le maintien du contexte!\\n\")\n",
        "\n",
        "# Initialiser l'agent avec un contexte\n",
        "agent_conversation = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an educational AI tutor specializing in agentic AI, RAG systems, and distributed computing. Be clear, concise, and build on previous questions to show continuity.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "def interactive_qa_agent():\n",
        "    \"\"\"\n",
        "    Boucle interactive pour le Q&A agent.\n",
        "    \"\"\"\n",
        "    turn_count = 0\n",
        "\n",
        "    while True:\n",
        "        turn_count += 1\n",
        "\n",
        "        # Simuler les entr√©es utilisateur avec des questions pr√©d√©finies\n",
        "        sample_questions = [\n",
        "            \"What is RAG (Retrieval-Augmented Generation)?\",\n",
        "            \"How does memory help an AI agent?\",\n",
        "            \"Give me an analogy relating RAG to something in daily life.\",\n",
        "            \"How would you combine these concepts in a real system?\"\n",
        "        ]\n",
        "\n",
        "        if turn_count <= len(sample_questions):\n",
        "            user_input = sample_questions[turn_count - 1]\n",
        "            print(f\"\\n[Turn {turn_count}]\")\n",
        "            print(f\"üë§ User: {user_input}\")\n",
        "        else:\n",
        "            # Apr√®s les questions pr√©d√©finies, permettre l'entr√©e utilisateur\n",
        "            user_input = input(\"\\nüë§ User: \").strip()\n",
        "            if not user_input:\n",
        "                continue\n",
        "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "                print(\"\\n‚úì Agent simulation ended. Goodbye!\")\n",
        "                break\n",
        "\n",
        "        # Ajouter la question √† la conversation\n",
        "        agent_conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Obtenir la r√©ponse\n",
        "        reply = chat_cycle(agent_conversation)\n",
        "        print(f\"ü§ñ AI: {reply}\")\n",
        "\n",
        "        # Ajouter la r√©ponse √† la conversation pour le contexte suivant\n",
        "        agent_conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "        # Arr√™ter apr√®s les questions pr√©d√©finies pour √©viter une boucle infinie en Colab\n",
        "        if turn_count >= len(sample_questions):\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"Questions pr√©d√©finies termin√©es.\")\n",
        "            print(\"Vous pouvez continuer √† poser des questions ou taper 'exit'.\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "# Lancer l'agent\n",
        "interactive_qa_agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0apTVDYafy7"
      },
      "source": [
        "## Summary & Key Learnings\n",
        "\n",
        "F√©licitations! Vous avez compl√©t√© le Lab 2. Voici ce que vous avez appris:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY1wAV5mafy7",
        "outputId": "05fd4e3f-c074-4f34-ac1d-a1775c0f5203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìö KEY LEARNINGS FROM LAB 2\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "1Ô∏è‚É£  SINGLE-TURN PROMPTING\n",
            "   ‚Ä¢ Les LLMs produisent des r√©ponses vari√©es m√™me pour un m√™me prompt\n",
            "   ‚Ä¢ Les contraintes (\"exactly N words\") augmentent la pr√©visibilit√©\n",
            "   ‚Ä¢ La temp√©rature (temperature parameter) permet de contr√¥ler la \"cr√©ativit√©\"\n",
            "\n",
            "2Ô∏è‚É£  MULTI-TURN CONVERSATIONS\n",
            "   ‚Ä¢ Les LLMs maintiennent le contexte tout au long d'√©changes successifs\n",
            "   ‚Ä¢ L'historique du message (message list) est crucial\n",
            "   ‚Ä¢ Ajouter les r√©ponses ant√©rieures √† la liste am√©liore la coh√©rence\n",
            "\n",
            "3Ô∏è‚É£  CONTEXT WINDOW LIMITS\n",
            "   ‚Ä¢ Les LLMs ont une fen√™tre de contexte maximale\n",
            "   ‚Ä¢ gpt-4o-mini supporte ~128K tokens (tr√®s large)\n",
            "   ‚Ä¢ Les vieux messages peuvent √™tre perdus dans de tr√®s longs contextes\n",
            "\n",
            "4Ô∏è‚É£  STRUCTURED OUTPUTS\n",
            "   ‚Ä¢ Les instructions syst√®me contr√¥lent le format de sortie\n",
            "   ‚Ä¢ JSON > Markdown tables pour le parsing programmatique\n",
            "   ‚Ä¢ Les contraintes de format am√©liorent la pr√©visibilit√©\n",
            "\n",
            "5Ô∏è‚É£  AGENTIC PATTERNS\n",
            "   ‚Ä¢ Les boucles conversationnelles peuvent simuler des agents\n",
            "   ‚Ä¢ La m√©moire (conversation history) = fondement des agents\n",
            "   ‚Ä¢ It√©ration + contexte = capacit√© de raisonnement am√©lior√©e\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "üéØ NEXT STEPS:\n",
            "   ‚Ä¢ Explorer system prompts plus sophistiqu√©s\n",
            "   ‚Ä¢ Impl√©menter des boucles de r√©flexion (chain-of-thought)\n",
            "   ‚Ä¢ Construire des agents avec des outils/actions\n",
            "   ‚Ä¢ Int√©grer une m√©moire persistante (RAG, embeddings)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "summary = \"\"\"\n",
        "üìö KEY LEARNINGS FROM LAB 2\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "1Ô∏è‚É£  SINGLE-TURN PROMPTING\n",
        "   ‚Ä¢ Les LLMs produisent des r√©ponses vari√©es m√™me pour un m√™me prompt\n",
        "   ‚Ä¢ Les contraintes (\"exactly N words\") augmentent la pr√©visibilit√©\n",
        "   ‚Ä¢ La temp√©rature (temperature parameter) permet de contr√¥ler la \"cr√©ativit√©\"\n",
        "\n",
        "2Ô∏è‚É£  MULTI-TURN CONVERSATIONS\n",
        "   ‚Ä¢ Les LLMs maintiennent le contexte tout au long d'√©changes successifs\n",
        "   ‚Ä¢ L'historique du message (message list) est crucial\n",
        "   ‚Ä¢ Ajouter les r√©ponses ant√©rieures √† la liste am√©liore la coh√©rence\n",
        "\n",
        "3Ô∏è‚É£  CONTEXT WINDOW LIMITS\n",
        "   ‚Ä¢ Les LLMs ont une fen√™tre de contexte maximale\n",
        "   ‚Ä¢ gpt-4o-mini supporte ~128K tokens (tr√®s large)\n",
        "   ‚Ä¢ Les vieux messages peuvent √™tre perdus dans de tr√®s longs contextes\n",
        "\n",
        "4Ô∏è‚É£  STRUCTURED OUTPUTS\n",
        "   ‚Ä¢ Les instructions syst√®me contr√¥lent le format de sortie\n",
        "   ‚Ä¢ JSON > Markdown tables pour le parsing programmatique\n",
        "   ‚Ä¢ Les contraintes de format am√©liorent la pr√©visibilit√©\n",
        "\n",
        "5Ô∏è‚É£  AGENTIC PATTERNS\n",
        "   ‚Ä¢ Les boucles conversationnelles peuvent simuler des agents\n",
        "   ‚Ä¢ La m√©moire (conversation history) = fondement des agents\n",
        "   ‚Ä¢ It√©ration + contexte = capacit√© de raisonnement am√©lior√©e\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "üéØ NEXT STEPS:\n",
        "   ‚Ä¢ Explorer system prompts plus sophistiqu√©s\n",
        "   ‚Ä¢ Impl√©menter des boucles de r√©flexion (chain-of-thought)\n",
        "   ‚Ä¢ Construire des agents avec des outils/actions\n",
        "   ‚Ä¢ Int√©grer une m√©moire persistante (RAG, embeddings)\n",
        "\"\"\"\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlkApHGWafy7",
        "outputId": "508a4c7f-ddcc-404b-e3a4-e0a4bde21f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Lab 2 Compl√©t√©!\n",
            "Vous avez acquis une compr√©hension solide des cycles prompt-response.\n",
            "Ces concepts sont fondamentaux pour construire des syst√®mes agentic avanc√©s.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n‚úÖ Lab 2 Compl√©t√©!\")\n",
        "print(\"Vous avez acquis une compr√©hension solide des cycles prompt-response.\")\n",
        "print(\"Ces concepts sont fondamentaux pour construire des syst√®mes agentic avanc√©s.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}