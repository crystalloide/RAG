{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystalloide/RAG/blob/main/LAB36_Agentic_AI_Tools_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ac2997",
      "metadata": {
        "id": "48ac2997"
      },
      "source": [
        "# LAB36 : Quâ€™est-ce qui dÃ©finit un outil en IA agentiqueÂ ?\n",
        "\n",
        "**ObjectifÂ :** Apprendre Ã  concevoir, implÃ©menter et exposer un outil quâ€™un agent peut appeler.\n",
        "\n",
        "**DurÃ©e estimÃ©eÂ :** 10 Ã  15Â minutes\n",
        "\n",
        "**LivrableÂ :** Un script Python fonctionnel dÃ©finissant 2 Ã  3Â outils et montrant comment un LLM peut les invoquer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "701efea8",
      "metadata": {
        "id": "701efea8"
      },
      "source": [
        "## Ã‰tape 1Â : Quâ€™est-ce quâ€™un outilÂ ? (Concept)\n",
        "\n",
        "Un **Tool** ou **outil** est toute fonction externe que lâ€™agent peut appeler pour Ã©tendre ses capacitÃ©s.\n",
        "\n",
        "**ExemplesÂ :**\n",
        "\n",
        "- Calculatrice\n",
        "- Recherche Web\n",
        "- RequÃªte de base de donnÃ©es\n",
        "- Appel dâ€™API\n",
        "\n",
        "**FormatÂ :** nom + description + fonction appelable\n",
        "\n",
        "Le LLM choisit quand invoquer lâ€™outil en fonction des instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba5a53c",
      "metadata": {
        "id": "aba5a53c"
      },
      "source": [
        "## Ã‰tape 2Â : Configuration\n",
        "\n",
        "Installation des bibliothÃ¨ques requisesÂ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "675fbb70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "675fbb70",
        "outputId": "353692f0-9c34-4578-ec0c-4f9ed3d0ca62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/84.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai python-dotenv requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c55ffbd1",
      "metadata": {
        "id": "c55ffbd1"
      },
      "source": [
        "**Configuration de la clÃ© API OpenAIÂ :**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e6862738",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6862738",
        "outputId": "d9ee5faa-ee7d-41e7-d006-ce4d295e8860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ ClÃ© API OpenAI chargÃ©e depuis les secrets Colab\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# RÃ©cupÃ©rer la clÃ© API depuis les secrets Colab\n",
        "# Pour ajouter : cliquez sur ðŸ”‘ dans le panneau de gauche\n",
        "try:\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "    print(\"âœ“ ClÃ© API OpenAI chargÃ©e depuis les secrets Colab\")\n",
        "except:\n",
        "    print(\"âš  Secrets Colab non configurÃ©s. Veuillez ajouter OPENAI_API_KEY.\")\n",
        "    print(\"Instructions : Cliquez sur ðŸ”‘ dans le panneau gauche > Ajouter un nouveau secret\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9ea7ab0",
      "metadata": {
        "id": "c9ea7ab0"
      },
      "source": [
        "## Ã‰tape 3Â : DÃ©finir des outils simples :\n",
        "\n",
        "CrÃ©ation de 3 outils de dÃ©monstrationÂ :\n",
        "\n",
        "1. **Calculator** - Ã‰valuation d'expressions mathÃ©matiques\n",
        "2. **Joke Generator** - Raconter des blagues sur un sujet donnÃ©\n",
        "3. **Weather** - Obtenir des informations mÃ©tÃ©orologiques fictives pour une ville (Ã  lâ€™aide de lâ€™API OpenMeteo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a328eb00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a328eb00",
        "outputId": "3ebdfdc1-d4c8-456a-870e-095e0cf5e5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Tools defined successfully\n",
            "Available tools: ['Calculator', 'Joke', 'Weather']\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import Tool\n",
        "import requests\n",
        "import math\n",
        "\n",
        "# 1. Calculator\n",
        "def calculator(expr: str):\n",
        "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return str(eval(expr))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# 2. Joke generator\n",
        "def joke(topic: str):\n",
        "    \"\"\"Generate a joke about a given topic.\"\"\"\n",
        "    return f\"Here's a {topic}-themed joke: Why did the {topic} cross the road? To learn Agentic AI!\"\n",
        "\n",
        "# 3. Weather (demo API call using Open-Meteo)\n",
        "def weather(city: str):\n",
        "    \"\"\"Get demo weather information for a city.\"\"\"\n",
        "    url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\"\n",
        "    try:\n",
        "        r = requests.get(url, timeout=10).json()\n",
        "        if \"results\" not in r or len(r[\"results\"]) == 0:\n",
        "            return f\"No weather info for {city}\"\n",
        "        coords = r[\"results\"][0]\n",
        "        return f\"{city} located at lat {coords['latitude']}, lon {coords['longitude']} (demo response).\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching weather: {e}\"\n",
        "\n",
        "# Define tools list\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=calculator,\n",
        "        description=\"Evaluate math expressions. Input should be a valid Python math expression as a string.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Joke\",\n",
        "        func=joke,\n",
        "        description=\"Tell a quick joke about a topic. Input should be a topic name as a string.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Weather\",\n",
        "        func=weather,\n",
        "        description=\"Get demo weather info for a city. Input should be a city name as a string.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "print(\"âœ“ Tools defined successfully\")\n",
        "print(f\"Available tools: {[t.name for t in tools]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82985ede",
      "metadata": {
        "id": "82985ede"
      },
      "source": [
        "**Test the tools individually:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e52e7f64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e52e7f64",
        "outputId": "588ca547-effc-4844-cec0-208f02bab7e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculator test: 120\n",
            "Joke test: Here's a robot-themed joke: Why did the robot cross the road? To learn Agentic AI!\n",
            "Weather test: Paris located at lat 48.85341, lon 2.3488 (demo response).\n"
          ]
        }
      ],
      "source": [
        "# Test de chaque Tool :\n",
        "print(\"Calculator test:\", calculator(\"12 * (7+3)\"))\n",
        "print(\"Joke test:\", joke(\"robot\"))\n",
        "print(\"Weather test:\", weather(\"Paris\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae14b5cc",
      "metadata": {
        "id": "ae14b5cc"
      },
      "source": [
        "## Ã‰tape 4Â : CrÃ©ation d'un agent \"intelligent\" :\n",
        "\n",
        "Nous allons maintenant crÃ©er un agent capable de choisir de lui-mÃªme lâ€™outil Ã  utiliser en fonction de la requÃªte de lâ€™utilisateur."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gWbyCbXS02K",
        "outputId": "7ec106ae-fea4-4fa6-ff09-59e8fe05ed45"
      },
      "id": "6gWbyCbXS02K",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import agents\n",
        "print(dir(agents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GsWs4sjS-xF",
        "outputId": "e4289d25-801d-4aa4-f5fd-cac2469d11f4"
      },
      "id": "5GsWs4sjS-xF",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AgentState', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'create_agent', 'factory', 'middleware', 'structured_output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from langchain.agents import create_agent\n",
        "print(inspect.signature(create_agent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx6m5VpoTOhb",
        "outputId": "7e9b83f2-4a41-40e7-839b-dfe6d6ca2197"
      },
      "id": "Zx6m5VpoTOhb",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(model: 'str | BaseChatModel', tools: 'Sequence[BaseTool | Callable[..., Any] | dict[str, Any]] | None' = None, *, system_prompt: 'str | SystemMessage | None' = None, middleware: 'Sequence[AgentMiddleware[StateT_co, ContextT]]' = (), response_format: 'ResponseFormat[ResponseT] | type[ResponseT] | dict[str, Any] | None' = None, state_schema: 'type[AgentState[ResponseT]] | None' = None, context_schema: 'type[ContextT] | None' = None, checkpointer: 'Checkpointer | None' = None, store: 'BaseStore | None' = None, interrupt_before: 'list[str] | None' = None, interrupt_after: 'list[str] | None' = None, debug: 'bool' = False, name: 'str | None' = None, cache: 'BaseCache[Any] | None' = None) -> 'CompiledStateGraph[AgentState[ResponseT], ContextT, _InputAgentState, _OutputAgentState[ResponseT]]'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_agent\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Create the agent with system prompt\n",
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=tools,\n",
        "    system_prompt=\"You are a helpful assistant. Use the tools available to answer questions accurately.\"\n",
        ")\n",
        "\n",
        "print(\"âœ“ Agent initialized successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9niac9sSVkr",
        "outputId": "87ae50f1-5a4d-4a00-ac85-3ad3aa20302e"
      },
      "id": "O9niac9sSVkr",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Agent initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Informations complÃ©mentaires :\n",
        "Cette version utilise la nouvelle API de **create_agent** avec les paramÃ¨tres nommÃ©s (model=, tools=, system_prompt=) qui correspondent Ã  la signature obtenue."
      ],
      "metadata": {
        "id": "oGnFaUvFRuTf"
      },
      "id": "oGnFaUvFRuTf"
    },
    {
      "cell_type": "markdown",
      "id": "58af8a39",
      "metadata": {
        "id": "58af8a39"
      },
      "source": [
        "## Ã‰tape 5Â : ExÃ©cution des requÃªtesÂ :\n",
        "\n",
        "Testons lâ€™agent avec diffÃ©rents types de requÃªtes et observons comment il choisit lâ€™outil appropriÃ©.\n",
        "\n",
        "**ðŸ‘‰ RemarqueÂ :**\n",
        "\n",
        "- Le LLM choisit un outil lorsquâ€™il le juge nÃ©cessaire.\n",
        "\n",
        "- Il n'y a pas besoin de coder en dur la logiqueÂ ; câ€™est lâ€™agent qui dÃ©cide.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e6f294",
      "metadata": {
        "id": "14e6f294"
      },
      "source": [
        "### RequÃªte 1Â : Calcul mathÃ©matique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f18c74ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f18c74ea",
        "outputId": "d77b560d-f60c-40bc-9c4d-e4219b4d27c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RÃ©sultat Final: {'messages': [HumanMessage(content='What is 12 * (7+3)?', additional_kwargs={}, response_metadata={}, id='36ec7899-b47a-4a64-a998-a60ab4db3828'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 160, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5qsaKPVWtXy6teYUxZEe2qqR9ZpX', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c2d58-2d4a-7561-b025-02e10c53de61-0', tool_calls=[{'name': 'Calculator', 'args': {'__arg1': '12 * (7 + 3)'}, 'id': 'call_AG5YeI5yj87l0ZhXmEYZ4CSe', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 160, 'output_tokens': 23, 'total_tokens': 183, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='120', name='Calculator', id='ca816d53-c6ca-44bb-9001-bb1849e02111', tool_call_id='call_AG5YeI5yj87l0ZhXmEYZ4CSe'), AIMessage(content='The result of \\\\( 12 \\\\times (7 + 3) \\\\) is 120.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 191, 'total_tokens': 212, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5qsb9TQnVyKCfKcWLRKmYuPR5uBP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2d58-349f-7092-925a-39189165d476-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 191, 'output_tokens': 21, 'total_tokens': 212, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "==================================================\n",
            "\n",
            "\n",
            "The result of \\( 12 \\times (7 + 3) \\) is 120.\n"
          ]
        }
      ],
      "source": [
        "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is 12 * (7+3)?\"}]})\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RÃ©sultat Final:\", response)\n",
        "print(\"=\"*50)\n",
        "print(\"\\n\")\n",
        "print(response['messages'][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2d9460",
      "metadata": {
        "id": "5d2d9460"
      },
      "source": [
        "### RequÃªte 2Â : Demander une blague"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4238fe99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4238fe99",
        "outputId": "5932b1b5-f887-4b40-d75c-2f5bc673b014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RÃ©sultat Final: {'messages': [HumanMessage(content='Tell me a joke about robots', additional_kwargs={}, response_metadata={}, id='76a38fb4-bfd5-49c7-87a5-e5259aa4a8f0'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 156, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5qshW4b9D5I08uIgExfKYvxhJOXM', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c2d58-4a56-7f81-a4bc-a6cd6b2f5ec9-0', tool_calls=[{'name': 'Joke', 'args': {'__arg1': 'robots'}, 'id': 'call_BltHogWs4w8obHltoy4oOtZY', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 156, 'output_tokens': 16, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Here's a robots-themed joke: Why did the robots cross the road? To learn Agentic AI!\", name='Joke', id='3c22b9be-3615-4400-9ddc-ce1fd369ebc7', tool_call_id='call_BltHogWs4w8obHltoy4oOtZY'), AIMessage(content=\"Here's a robot-themed joke for you: Why did the robots cross the road? To learn Agentic AI!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 200, 'total_tokens': 223, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5qshcDbDEUUPg9IFGzwkljAtZHLE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2d58-4cfe-75c1-8d87-dc5eaf536a2f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 200, 'output_tokens': 23, 'total_tokens': 223, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "==================================================\n",
            "\n",
            "\n",
            "Here's a robot-themed joke for you: Why did the robots cross the road? To learn Agentic AI!\n"
          ]
        }
      ],
      "source": [
        "# Test avec les blagues\n",
        "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about robots\"}]})\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RÃ©sultat Final:\", response)\n",
        "print(\"=\"*50)\n",
        "print(\"\\n\")\n",
        "print(response['messages'][-1].content)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a6e6ec",
      "metadata": {
        "id": "49a6e6ec"
      },
      "source": [
        "### RequÃªte 3Â : Informations mÃ©tÃ©orologiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "63a5fd0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63a5fd0a",
        "outputId": "e3578d6c-f02c-4aca-cb10-886cec65a1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RÃ©sultat Final: {'messages': [HumanMessage(content=\"What's the weather in Paris?\", additional_kwargs={}, response_metadata={}, id='5ec7a84c-d9d6-48b7-84ce-98589b92c56a'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 156, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5qsnkRlvlf1msEfkqoXxQ1uzQcYV', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c2d58-64ff-7cb1-9adc-26ee25fe6307-0', tool_calls=[{'name': 'Weather', 'args': {'__arg1': 'Paris'}, 'id': 'call_3Fmu5zAslcUCWWep0VNN45Km', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 156, 'output_tokens': 16, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Paris located at lat 48.85341, lon 2.3488 (demo response).', name='Weather', id='6bd9bccf-875c-4c9d-ba91-0958d710bfe4', tool_call_id='call_3Fmu5zAslcUCWWep0VNN45Km'), AIMessage(content='The weather in Paris is currently not available in detail, but the city is located at latitude 48.85341 and longitude 2.3488. If you need specific weather conditions like temperature or precipitation, please check a weather service for the latest updates.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 199, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5qspOWYonFKUwZ7wanyyAhfkysFk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2d58-6bea-7370-931e-e16b0d08e89b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 199, 'output_tokens': 53, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "==================================================\n",
            "\n",
            "\n",
            "The weather in Paris is currently not available in detail, but the city is located at latitude 48.85341 and longitude 2.3488. If you need specific weather conditions like temperature or precipitation, please check a weather service for the latest updates.\n"
          ]
        }
      ],
      "source": [
        "# Test avec la mÃ©tÃ©o\n",
        "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Paris?\"}]})\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RÃ©sultat Final:\", response)\n",
        "print(\"=\"*50)\n",
        "print(\"\\n\")\n",
        "print(response['messages'][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6e3ef5",
      "metadata": {
        "id": "5e6e3ef5"
      },
      "source": [
        "### RequÃªte 4Â : RequÃªte complexe nÃ©cessitant un raisonnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "688ffd1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "688ffd1a",
        "outputId": "65650aaa-fc85-4282-fbea-d0fd5daa70cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RÃ©sultat Final: {'messages': [HumanMessage(content='Calculate 25 squared, then tell me a joke about math.', additional_kwargs={}, response_metadata={}, id='ae018d63-dafe-4592-a6ec-d182ebce1735'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 163, 'total_tokens': 213, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5quQWrEqUfkYhrIgpLukJtxzEYdp', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c2d59-efbe-7023-8843-6fb5b84734c6-0', tool_calls=[{'name': 'Calculator', 'args': {'__arg1': '25**2'}, 'id': 'call_Dvaj8R3uPPe4Wj1j4YENTc2A', 'type': 'tool_call'}, {'name': 'Joke', 'args': {'__arg1': 'math'}, 'id': 'call_BEKu5vblRSNDvnWvzvumZ5DZ', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 163, 'output_tokens': 50, 'total_tokens': 213, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='625', name='Calculator', id='8149f741-64c0-4599-a760-599d4369430c', tool_call_id='call_Dvaj8R3uPPe4Wj1j4YENTc2A'), ToolMessage(content=\"Here's a math-themed joke: Why did the math cross the road? To learn Agentic AI!\", name='Joke', id='44ba26ba-5141-4b14-a3f4-d5abb9039457', tool_call_id='call_BEKu5vblRSNDvnWvzvumZ5DZ'), AIMessage(content=\"25 squared is 625. \\n\\nAnd here's a math-themed joke for you: Why did the math cross the road? To learn Agentic AI!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 248, 'total_tokens': 279, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5quSJw0EVj6o7ikf5MJ4s2ebpkH3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2d59-f4a0-7673-8d5f-fe3f16061a50-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 248, 'output_tokens': 31, 'total_tokens': 279, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "==================================================\n",
            "\n",
            "\n",
            "25 squared is 625. \n",
            "\n",
            "And here's a math-themed joke for you: Why did the math cross the road? To learn Agentic AI!\n"
          ]
        }
      ],
      "source": [
        "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Calculate 25 squared, then tell me a joke about math.\"}]})\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RÃ©sultat Final:\", response)\n",
        "print(\"=\"*50)\n",
        "print(\"\\n\")\n",
        "print(response['messages'][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f95d0677",
      "metadata": {
        "id": "f95d0677"
      },
      "source": [
        "## Ã‰tape 6Â : Mini-projet (optionnel)Â :\n",
        "\n",
        "**DÃ©fiÂ :** Ajoutez votre propre outil personnalisÃ© Ã  lâ€™agentÂ !\n",
        "\n",
        "Voici quelques idÃ©esÂ :\n",
        "\n",
        "1. **search_github**Â : Rechercher des dÃ©pÃ´ts GitHub (utiliser lâ€™API GitHub)\n",
        "\n",
        "2. **summarize_url**Â : RÃ©cupÃ©rer et rÃ©sumer une page web\n",
        "\n",
        "3. **convert_currency**Â : Convertir des devises\n",
        "\n",
        "4. **random_fact**Â : Afficher un fait alÃ©atoire dâ€™une liste\n",
        "\n",
        "5. **text_stats**Â : Compter les mots, les caractÃ¨res et les phrases dâ€™un texte\n",
        "\n",
        "\n",
        "```\n",
        "```\n",
        "  **ModÃ¨le pour crÃ©er un nouvel outilÂ :**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import Tool\n",
        "\n",
        "# Example: Text statistics tool\n",
        "def text_stats(text: str):\n",
        "    \"\"\"Analyze text and return statistics.\"\"\"\n",
        "    words = len(text.split())\n",
        "    chars = len(text)\n",
        "    sentences = text.count('.') + text.count('!') + text.count('?')\n",
        "    return f\"Text stats: {words} words, {chars} characters, {sentences} sentences.\"\n",
        "\n",
        "# Add the new tool\n",
        "new_tool = Tool(\n",
        "    name=\"TextStats\",\n",
        "    func=text_stats,\n",
        "    description=\"Analyze text and return statistics (word count, character count, sentence count). Input should be a text string.\"\n",
        ")\n",
        "\n",
        "# Create updated tools list\n",
        "extended_tools = tools + [new_tool]\n",
        "\n",
        "# Reinitialize agent with new tool using create_agent\n",
        "extended_agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=extended_tools,\n",
        "    system_prompt=\"You are a helpful assistant. Use the tools available to answer questions accurately.\"\n",
        ")\n",
        "\n",
        "print(\"âœ“ Extended agent created with new tool\")\n",
        "print(f\"Available tools: {[t.name for t in extended_tools]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL9cTcwUc4EQ",
        "outputId": "06bcf5d9-e373-479a-e8c2-c1bec1d5ef51"
      },
      "id": "sL9cTcwUc4EQ",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Extended agent created with new tool\n",
            "Available tools: ['Calculator', 'Joke', 'Weather', 'TextStats']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396c5679",
      "metadata": {
        "id": "396c5679"
      },
      "source": [
        "**Test de l'agent Ã©tenduÂ :**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = extended_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"List the tools you have at your disposal.'\"}]})\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RÃ©sultat Final:\", response)\n",
        "print(\"=\"*50)\n",
        "print(\"\\n\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVAKjXTVd6FR",
        "outputId": "b7ec81f1-1245-49fe-bbf6-91e36431d9cd"
      },
      "id": "iVAKjXTVd6FR",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RÃ©sultat Final: {'messages': [HumanMessage(content=\"List the tools you have at your disposal.'\", additional_kwargs={}, response_metadata={}, id='821a11c4-579e-4d5b-9a3a-dfaae6db3337'), AIMessage(content='I have the following tools at my disposal:\\n\\n1. **Calculator**: Evaluates math expressions.\\n2. **Joke**: Tells a quick joke about a specified topic.\\n3. **Weather**: Provides demo weather information for a specified city.\\n4. **TextStats**: Analyzes text and returns statistics such as word count, character count, and sentence count.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 202, 'total_tokens': 281, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5rReWSo8cchPGklXjGxpgi7lwCWm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2d79-59f8-78a1-bca6-40281a7f0397-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 202, 'output_tokens': 79, 'total_tokens': 281, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "==================================================\n",
            "\n",
            "\n",
            "I have the following tools at my disposal:\n",
            "\n",
            "1. **Calculator**: Evaluates math expressions.\n",
            "2. **Joke**: Tells a quick joke about a specified topic.\n",
            "3. **Weather**: Provides demo weather information for a specified city.\n",
            "4. **TextStats**: Analyzes text and returns statistics such as word count, character count, and sentence count.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e8bec37a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8bec37a",
        "outputId": "321af88a-59cd-4e1e-b26c-49b5633a656a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "RÃ©sultat Final: {'messages': [HumanMessage(content=\"Analyze this text and give the tools you haved used if any : 'Agentic AI is amazing! It can use tools. This is the future.'\", additional_kwargs={}, response_metadata={}, id='223beb56-11bb-4f2e-98c5-afdccbd4bf59'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 224, 'total_tokens': 255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5rRFHNTXfbxMzBX9kXcWORjf9Hfm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c2d78-fb06-7ae0-986b-c542f279d333-0', tool_calls=[{'name': 'TextStats', 'args': {'__arg1': 'Agentic AI is amazing! It can use tools. This is the future.'}, 'id': 'call_hhwCiK8mCTiEkxIGwDuxe7g7', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 224, 'output_tokens': 31, 'total_tokens': 255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Text stats: 12 words, 60 characters, 3 sentences.', name='TextStats', id='f5fbfaec-1825-4537-8bcb-f0f80fec1ceb', tool_call_id='call_hhwCiK8mCTiEkxIGwDuxe7g7'), AIMessage(content='I analyzed the text using the **TextStats** tool. Here are the statistics:\\n\\n- **Word Count:** 12\\n- **Character Count:** 60\\n- **Sentence Count:** 3\\n\\nIf you need any further analysis or information, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 278, 'total_tokens': 334, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6c0d1490cb', 'id': 'chatcmpl-D5rRGedeaxewtyIxzc1QcxzNv9gMK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2d78-fef8-7a92-90a7-143cda17dc12-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 278, 'output_tokens': 56, 'total_tokens': 334, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "==================================================\n",
            "\n",
            "\n",
            "I analyzed the text using the **TextStats** tool. Here are the statistics:\n",
            "\n",
            "- **Word Count:** 12\n",
            "- **Character Count:** 60\n",
            "- **Sentence Count:** 3\n",
            "\n",
            "If you need any further analysis or information, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "response = extended_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Analyze this text and give the tools you haved used if any : 'Agentic AI is amazing! It can use tools. This is the future.'\"}]})\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RÃ©sultat Final:\", response)\n",
        "print(\"=\"*50)\n",
        "print(\"\\n\")\n",
        "print(response['messages'][-1].content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169250b9",
      "metadata": {
        "id": "169250b9"
      },
      "source": [
        "### Ã€ vous de jouerÂ ! ðŸš€\n",
        "\n",
        "CrÃ©ez votre propre outil personnalisÃ© ci-dessousÂ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a39ffb8",
      "metadata": {
        "id": "7a39ffb8"
      },
      "outputs": [],
      "source": [
        "# TODO: DÃ©finir ici la fonction de votre outil personnalisÃ©\n",
        "def my_custom_tool(input_param: str):\n",
        "    \"\"\"Description of what your tool does.\"\"\"\n",
        "    # Your implementation here\n",
        "    return \"Your result\"\n",
        "\n",
        "# TODO: Create the Tool object\n",
        "# my_tool = Tool(\n",
        "#     name=\"MyTool\",\n",
        "#     func=my_custom_tool,\n",
        "#     description=\"Description permettant Ã  l'agent de comprendre quand utiliser cet outil.\"\n",
        "# )\n",
        "\n",
        "# TODO: Ajouter aux outils et testerÂ !"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99fb225a",
      "metadata": {
        "id": "99fb225a"
      },
      "source": [
        "## Conclusion :\n",
        "\n",
        "Dans ce TP, nous avons (re)vu :\n",
        "\n",
        "âœ… Ce qu'est un outil dans le contexte de l'IA agentique\n",
        "\n",
        "âœ… Comment dÃ©finir des outils Ã  l'aide de la classe `Tool` de LangChain\n",
        "\n",
        "âœ… Comment crÃ©er un agent capable de sÃ©lectionner et d'utiliser intelligemment des outils\n",
        "\n",
        "âœ… Comment l'agent utilise ReAct (Reasoning + Acting) pour rÃ©soudre des problÃ¨mes\n",
        "\n",
        "âœ… Comment Ã©tendre les capacitÃ©s d'un agent avec des outils personnalisÃ©s\n",
        "\n",
        "**Points clÃ©sÂ :**\n",
        "\n",
        "- Les outils Ã©tendent les capacitÃ©s de l'agent au-delÃ  de la simple gÃ©nÃ©ration de langage\n",
        "- L'agent dÃ©cide de maniÃ¨re autonome quel outil utiliser en fonction de la requÃªte\n",
        "- Les outils doivent avoir des noms et des descriptions clairs pour Ãªtre compris par le LLM\n",
        "- Plusieurs outils peuvent Ãªtre combinÃ©s pour rÃ©soudre des tÃ¢ches complexes\n",
        "\n",
        "**Prochaines Ã©tapesÂ :**\n",
        "\n",
        "- ExpÃ©rimenter avec des outils plus complexes (API, bases de donnÃ©es, opÃ©rations sur les fichiers)\n",
        "\n",
        "- Essayer diffÃ©rents types d'agents (conversationnel, chat structurÃ©, etc.)\n",
        "\n",
        "- CrÃ©er une application concrÃ¨te combinant plusieurs outils\n",
        "\n",
        "- Explorer la gestion des erreurs et la validation des outils"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}