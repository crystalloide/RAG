{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystalloide/RAG/blob/main/LAB48_Fondamentaux_de_LangChain_et_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LAB48 : D√©couverte de LangChain et LangGraph\n",
        "\n",
        "**Objectif¬†:** Comprendre les diff√©rences entre les cha√Ænes LangChain et les graphes LangGraph, et ex√©cuter des exemples minimaux pour chacun.\n",
        "\n",
        "**Dur√©e estim√©e¬†:** 15 √† 20¬†minutes\n",
        "\n",
        "**Livrable¬†:** Un notebook ex√©cutant les deux frameworks sur la m√™me t√¢che et illustrant les diff√©rences structurelles."
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Setup :\n",
        "\n",
        "Installation des packages requis et configuration de la cl√© API."
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation des packages requiss\n",
        "!pip install -q langchain langchain-openai langgraph openai python-dotenv"
      ],
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9046c267-fa26-4070-d4dd-7145a3d9febe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/84.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# R√©cup√©ration de la cl√© API depuis les secrets Colab\n",
        "# Pour ajouter : cliquez sur üîë dans le panneau de gauche\n",
        "try:\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "    print(\"‚úì Cl√© API OpenAI charg√©e depuis les secrets Colab\")\n",
        "except:\n",
        "    print(\"‚ö† Secrets Colab non configur√©s. Veuillez ajouter OPENAI_API_KEY.\")\n",
        "    print(\"Instructions : Cliquez sur üîë dans le panneau gauche > Ajouter un nouveau secret\")"
      ],
      "metadata": {
        "id": "api_key",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808dcf65-193e-44cb-d585-20a1864de133"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Cl√© API OpenAI charg√©e depuis les secrets Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2) LangChain : construction d'une une cha√Æne simple :\n",
        "Id√©e centrale de LangChain¬†: cha√Ænes s√©quentielles d‚Äôappels LLM et de mod√®les de prompts."
      ],
      "metadata": {
        "id": "langchain"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 1. Initialisation du mod√®le\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# 2. D√©finition du template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a concise summarizer.\"),\n",
        "    (\"user\", \"Summarize this text in 3 bullet points:\\n{text}\")\n",
        "])\n",
        "\n",
        "# 3. Cr√©ation de la cha√Æne avec LCEL (le pipe '|')\n",
        "# On ajoute StrOutputParser() pour extraire directement le texte de la r√©ponse\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Texte d'exemple\n",
        "# sample_text = \"\"\"\n",
        "# Agentic AI allows autonomous decision-making by combining reasoning, memory, and tools.\n",
        "# It enables multi-agent collaboration and domain-specific applications.\n",
        "# Challenges include safety, alignment, and evaluation.\n",
        "# \"\"\"\n",
        "\n",
        "sample_text = \"\"\"\n",
        "L'IA agentive permet une prise de d√©cision autonome en combinant raisonnement, m√©moire et outils.\n",
        "Elle permet la collaboration multi-agents et les applications sp√©cifiques √† un domaine.\n",
        "Les d√©fis incluent la s√©curit√©, l'alignement et l'√©valuation.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 4. Ex√©cution (on utilise .invoke au lieu de .run)\n",
        "print(\"\\n--- LangChain Output ---\\n\")\n",
        "result = chain.invoke({\"text\": sample_text})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "langchain_chain",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bcb61e-0ae9-4eb8-9b18-abd8a480a826"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LangChain Output ---\n",
            "\n",
            "- L'IA agentive facilite la prise de d√©cision autonome gr√¢ce √† l'int√©gration du raisonnement, de la m√©moire et d'outils.\n",
            "- Elle favorise la collaboration entre plusieurs agents et des applications sp√©cialis√©es dans divers domaines.\n",
            "- Les principaux d√©fis √† relever sont la s√©curit√©, l'alignement et l'√©valuation des syst√®mes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üëâ Point cl√© √† retenir\n",
        "\n",
        "LangChain facilite l'int√©gration des LLM, des mod√®les (templates) et des outils (tools) dans un pipeline lin√©aire."
      ],
      "metadata": {
        "id": "langchain_takeaway"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) LangGraph : construction d'un graphe simple¬†:\n",
        "\n",
        "Id√©e fondamentale de LangGraph¬†:\n",
        "- graphes orient√©s\n",
        "- avec √©tat (stateful)\n",
        "- compos√©s de n≈ìuds (Directid Graphs)\n",
        "- avec boucles\n",
        "- avec banchements\n",
        "- avec m√©moire"
      ],
      "metadata": {
        "id": "langgraph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict\n",
        "\n",
        "# Define state\n",
        "class State(TypedDict):\n",
        "    text: str\n",
        "    summary: str\n",
        "\n",
        "# Define nodes\n",
        "def summarize(state: State):\n",
        "    response = llm.invoke(f\"Summarize this text in 2 sentences:\\n{state['text']}\")\n",
        "    return {\"summary\": response.content}\n",
        "\n",
        "def reflect(state: State):\n",
        "    response = llm.invoke(f\"Critique this summary: {state['summary']}\")\n",
        "    return {\"summary\": state['summary'] + \"\\nCritique: \" + response.content}\n",
        "\n",
        "# Build graph\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"summarize\", summarize)\n",
        "workflow.add_node(\"reflect\", reflect)\n",
        "workflow.set_entry_point(\"summarize\")\n",
        "workflow.add_edge(\"summarize\", \"reflect\")\n",
        "workflow.add_edge(\"reflect\", END)\n",
        "app = workflow.compile()\n",
        "\n",
        "# Run\n",
        "print(\"\\n--- LangGraph Output ---\\n\")\n",
        "result = app.invoke({\"text\": sample_text})\n",
        "print(result[\"summary\"])"
      ],
      "metadata": {
        "id": "langgraph_graph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcb9e9f-ce9f-4c4f-eef1-e72da5c85f18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LangGraph Output ---\n",
            "\n",
            "L'IA agentive facilite la prise de d√©cision autonome en int√©grant raisonnement, m√©moire et outils, tout en favorisant la collaboration entre plusieurs agents et des applications sp√©cialis√©es. Cependant, elle pose des d√©fis en mati√®re de s√©curit√©, d'alignement et d'√©valuation.\n",
            "Critique: Cette synth√®se pr√©sente de mani√®re concise les avantages et les d√©fis associ√©s √† l'IA agentive. Voici quelques points de critique :\n",
            "\n",
            "1. **Clart√© et pr√©cision** : Le terme \"IA agentive\" pourrait √™tre mieux d√©fini pour les lecteurs qui ne sont pas familiers avec le concept. Une br√®ve explication de ce que cela implique renforcerait la compr√©hension.\n",
            "\n",
            "2. **√âquilibre** : Bien que les avantages soient mentionn√©s, la formulation pourrait donner l'impression que les d√©fis sont secondaires. Il serait b√©n√©fique d'accorder plus de poids aux d√©fis, en expliquant bri√®vement chacun d'eux (s√©curit√©, alignement, √©valuation) pour souligner leur importance.\n",
            "\n",
            "3. **Exemples concrets** : L'ajout d'exemples sp√©cifiques d'applications ou de contextes o√π l'IA agentive est utilis√©e pourrait enrichir le r√©sum√© et le rendre plus tangible.\n",
            "\n",
            "4. **Structure** : La phrase pourrait √™tre scind√©e pour am√©liorer la lisibilit√©. Par exemple, en s√©parant les avantages des d√©fis, le lecteur pourrait mieux saisir les deux aspects.\n",
            "\n",
            "5. **Terminologie** : L'utilisation de termes comme \"alignement\" et \"√©valuation\" pourrait √™tre clarifi√©e. Par exemple, expliquer ce que signifie \"alignement\" dans le contexte de l'IA aiderait √† √©viter toute ambigu√Øt√©.\n",
            "\n",
            "En r√©sum√©, bien que la synth√®se soit informative, elle gagnerait √† √™tre plus explicite et √©quilibr√©e, tout en fournissant des exemples concrets pour illustrer les points soulev√©s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extrait de code :\n",
        "- Vous pouvez utiliser **Mermaid** (langage de script utilis√© pour g√©n√©rer des diagrammes √† partir de texte) pour d√©finir le sens de lecture du graphique.\n",
        "- **Mermaid** : https://mermaid.ai/app/projects\n",
        "\n",
        "- **graph LR** signifie \"graphique de gauche √† droite\" :\n",
        "\n",
        "```\n",
        "graph LR\n",
        "  START((START)) --> summarize[summarize]\n",
        "  summarize --> reflect[reflect]\n",
        "  reflect --> END((END))\n",
        "  \n",
        "  subgraph State\n",
        "    text\n",
        "    summary\n",
        "  end\n",
        "```\n",
        "\n",
        "### **Analyse des composants** :\n",
        "Voici comment les donn√©es circulent √† travers ton graphe :\n",
        "\n",
        "- L'√âtat (**State**) : C'est la m√©moire partag√©e. Au d√©but, on fournit le texte **text**. Apr√®s le premier n≈ìud, l'√©tat contient √† la fois **text** et **summary**.\n",
        "\n",
        "- Point d'entr√©e **START**: Le graphe commence toujours par le n≈ìud d√©fini dans set_entry_point, ici summarize.\n",
        "\n",
        "- N≈ìud **summarize** : Prend le texte brut, g√©n√®re un r√©sum√© via l'LLM, et met √† jour la cl√© summary dans l'√©tat.\n",
        "\n",
        "- N≈ìud **reflect** : R√©cup√®re le summary cr√©√© √† l'√©tape pr√©c√©dente, demande une critique √† l'LLM, et l'ajoute √† la suite du r√©sum√© existant.\n",
        "\n",
        "- Fin (**END**) : Une fois que reflect a termin√© son ex√©cution, le graphe atteint le marqueur sp√©cial END et s'arr√™te.\n",
        "\n",
        "**Note** :\n",
        "- Dans ce sch√©ma, l'√©tat est \"persistant\" entre les n≈ìuds.\n",
        "- Chaque fonction ne renvoie que la modification qu'elle souhaite apporter\n",
        "- et LangGraph s'occupe de fusionner cela dans l'objet State global."
      ],
      "metadata": {
        "id": "4Hs1unWys6Qb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üëâ Point cl√© √† retenir\n",
        "\n",
        "LangGraph est con√ßu pour la logique de branchement et les boucles de r√©troaction :\n",
        "- il est plus flexible que les cha√Ænes s√©quentielles de LangChain."
      ],
      "metadata": {
        "id": "langgraph_takeaway"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Comparaison de LangChain vs LangGraph :\n",
        "\n",
        "| Aspect | LangChain | LangGraph |\n",
        "|--------|-----------|----------|\n",
        "| **Abstraction** | Chains (linear pipelines) | Graphs (nodes + edges + state) |\n",
        "| **Avantages** | Simple, fast to prototype | Complex workflows, feedback loops |\n",
        "| **Usages** | Small apps, demos, simple RAG | Agent orchestration, multi-step reasoning |\n",
        "| **M√©moire** | Ad-hoc (ConversationBuffer) | Built-in state objects |\n",
        "| **Design style** | Prompt-template centric | State-machine centric |"
      ],
      "metadata": {
        "id": "comparison"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Mini-projet (optionnel)\n",
        "\n",
        "Essayez les exercices suivants¬†:\n",
        "\n",
        "1. Modifiez la cha√Æne LangChain pour inclure une 2nde √©tape (par exemple, un rewriter de style).\n",
        "\n",
        "2. Modifiez le graphe LangGraph pour ajouter une boucle¬†: apr√®s chaque critique, relancez `summarize` jusqu‚Äô√† ce que la critique soit ¬´¬†satisfied¬†¬ª.\n",
        "\n",
        "3. Comparez les r√©sultats.\n"
      ],
      "metadata": {
        "id": "mini_project"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice n¬∞1 : LangChain avec une cha√Æne √† 2 √©tapes :\n",
        "\n",
        "Remarque :\n",
        "- Aujourd'hui, LangChain recommande d'utiliser le \"Pipe\" (|).\n",
        "- C'est beaucoup plus lisible, plus rapide et plus facile √† d√©boguer."
      ],
      "metadata": {
        "id": "exercise1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Configuration des prompts\n",
        "# summarize_prompt = ChatPromptTemplate.from_template(\"Summarize this text in 3 bullet points:\\n{text}\")\n",
        "# rewrite_prompt = ChatPromptTemplate.from_template(\"Rewrite this summary in a formal, academic style:\\n{summary}\")\n",
        "summarize_prompt = ChatPromptTemplate.from_template(\"R√©sume ce texte en 3 points cl√©s¬†:\\n{text}\")\n",
        "rewrite_prompt = ChatPromptTemplate.from_template(\"R√©√©crit ce r√©sum√© dans un style formel et acad√©mique¬†::\\n{summary}\")\n",
        "\n",
        "# Cr√©ation de la cha√Æne moderne LCEL (LangChain Expression Language)\n",
        "# On utilise un dictionnaire pour transmettre le r√©sultat de l'√©tape 1 √† l'√©tape 2\n",
        "chain = (\n",
        "    {\"summary\": summarize_prompt | llm | StrOutputParser()}\n",
        "    | RunnablePassthrough.assign(\n",
        "        formal_summary = lambda x: (rewrite_prompt | llm | StrOutputParser()).invoke({\"summary\": x[\"summary\"]})\n",
        "    )\n",
        ")\n",
        "\n",
        "# Ex√©cution\n",
        "result = chain.invoke({\"text\": sample_text})\n",
        "\n",
        "print(f\"R√©sum√©:\\n{result['summary']}\")\n",
        "print(f\"\\nR√©√©criture en style acad√©mique formel:\\n{result['formal_summary']}\")"
      ],
      "metadata": {
        "id": "exercise1_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958fea47-9cbd-48ef-e3ef-57d27dc21a39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R√©sum√©:\n",
            "1. L'IA agentive facilite la prise de d√©cision autonome en int√©grant raisonnement, m√©moire et outils.\n",
            "2. Elle favorise la collaboration entre plusieurs agents et permet des applications sp√©cialis√©es dans divers domaines.\n",
            "3. Les principaux d√©fis √† relever concernent la s√©curit√©, l'alignement des objectifs et l'√©valuation des performances.\n",
            "\n",
            "R√©√©criture en style acad√©mique formel:\n",
            "L'intelligence artificielle agentive constitue un outil facilitant la prise de d√©cision autonome, en int√©grant des m√©canismes de raisonnement, de m√©moire et d'outils adapt√©s. Elle encourage √©galement la collaboration entre plusieurs agents, permettant ainsi le d√©veloppement d'applications sp√©cialis√©es dans divers domaines d'activit√©. Toutefois, les principaux d√©fis √† surmonter dans ce domaine concernent la s√©curit√©, l'alignement des objectifs des agents et l'√©valuation de leurs performances.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice n¬∞2 : LangGraph avec une boucle de Feedback :"
      ],
      "metadata": {
        "id": "exercise2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add a loop that re-summarizes until the critique is positive\n",
        "\n",
        "from typing import Literal\n",
        "\n",
        "class LoopState(TypedDict):\n",
        "    text: str\n",
        "    summary: str\n",
        "    critique: str\n",
        "    iteration: int\n",
        "\n",
        "def summarize_v2(state: LoopState):\n",
        "    iteration = state.get('iteration', 0) + 1\n",
        "    response = llm.invoke(f\"Summarize this text in 2 sentences:\\n{state['text']}\")\n",
        "    return {\"summary\": response.content, \"iteration\": iteration}\n",
        "\n",
        "def critique(state: LoopState):\n",
        "    response = llm.invoke(\n",
        "        #f\"Rate this summary from 1-10 and explain why. Summary: {state['summary']}\\n\"\n",
        "        #f\"Return ONLY the number followed by your explanation.\"\n",
        "        f\"√âvalue ce r√©sum√© de 1 √† 10 et explique pourquoi. R√©sum√©: {state['summary']}\\n\"\n",
        "        f\"Renvoie UNIQUEMENT le nombre suivi de ton explication.\"\n",
        "    )\n",
        "    return {\"critique\": response.content}\n",
        "\n",
        "def should_continue(state: LoopState) -> Literal[\"summarize\", \"end\"]:\n",
        "    \"\"\"Check si le score \"critique\" est >= 8 ou si on a fait 3 it√©rations\"\"\"\n",
        "    critique_text = state.get('critique', '')\n",
        "    iteration = state.get('iteration', 0)\n",
        "\n",
        "    # Extract score (first number in critique)\n",
        "    import re\n",
        "    match = re.search(r'\\d+', critique_text)\n",
        "    score = int(match.group()) if match else 0\n",
        "\n",
        "    if score >= 9 or iteration >= 3:\n",
        "        return \"end\"\n",
        "    return \"summarize\"\n",
        "\n",
        "# Construction du graph avec une boucle :\n",
        "workflow_loop = StateGraph(LoopState)\n",
        "workflow_loop.add_node(\"summarize\", summarize_v2)\n",
        "workflow_loop.add_node(\"critique\", critique)\n",
        "workflow_loop.set_entry_point(\"summarize\")\n",
        "workflow_loop.add_edge(\"summarize\", \"critique\")\n",
        "workflow_loop.add_conditional_edges(\n",
        "    \"critique\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"summarize\": \"summarize\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "app_loop = workflow_loop.compile()\n",
        "\n",
        "# Ex√©cution : on fait 3 it√©rations maximum ou √† partir d'une note de 9+\n",
        "print(\"\\n--- LangGraph avec boucle de Feedback ---\\n\")\n",
        "result = app_loop.invoke({\"text\": sample_text, \"iteration\": 0})\n",
        "print(f\"Iterations: {result['iteration']}\")\n",
        "print(f\"\\nR√©sum√© final:\\n-{result['summary']}\")\n",
        "print(f\"\\nCritique finale:\\n- Note : {result['critique']}\")"
      ],
      "metadata": {
        "id": "exercise2_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8815e4f-0aa0-4440-cc50-768e50ab8e98"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LangGraph avec boucle de Feedback ---\n",
            "\n",
            "Iterations: 3\n",
            "\n",
            "R√©sum√© final:\n",
            "-L'IA agentive facilite la prise de d√©cision autonome en int√©grant raisonnement, m√©moire et outils, tout en favorisant la collaboration entre plusieurs agents et des applications sp√©cialis√©es. Cependant, elle pose des d√©fis en mati√®re de s√©curit√©, d'alignement et d'√©valuation.\n",
            "\n",
            "Critique finale:\n",
            "- Note : 8\n",
            "\n",
            "Ce r√©sum√© est concis et couvre les points essentiels concernant l'IA agentive, notamment ses avantages en mati√®re de prise de d√©cision autonome et de collaboration, ainsi que les d√©fis qu'elle pose. Cependant, il pourrait √™tre am√©lior√© en fournissant des exemples concrets ou en d√©veloppant davantage les d√©fis mentionn√©s pour donner une meilleure compr√©hension du sujet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Conclusion et synth√®se:\n",
        "\n",
        "En terminant ce TP, vous savez d√©sormais comment¬†:\n",
        "\n",
        "- Cr√©er une cha√Æne LangChain de base\n",
        "\n",
        "- Cr√©er un workflow LangGraph avec gestion d'√©tat\n",
        "\n",
        "- Choisir le framework le plus adapt√© √† chaque situation\n",
        "\n",
        "- Construire des cha√Ænes √† plusieurs √©tapes et des boucles de r√©troaction\n",
        "\n",
        "### Principales diff√©rences¬†:\n",
        "\n",
        "- **LangChain**¬†: Id√©al pour les workflows simples et lin√©aires et le prototypage rapide\n",
        "\n",
        "- **LangGraph**¬†: Id√©al pour les workflows complexes avec embranchements, boucles et gestion d'√©tat"
      ],
      "metadata": {
        "id": "completion"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ressources suppl√©mentaires pour aller plus loin :\n",
        "\n",
        "- [Documentation de LangChain](https://python.langchain.com/)\n",
        "- [Documentation de LangGraph](https://langchain-ai.github.io/langgraph/)\n",
        "- [R√©f√©rence de l'API OpenAI](https://platform.openai.com/docs/api-reference)"
      ],
      "metadata": {
        "id": "resources"
      }
    }
  ]
}